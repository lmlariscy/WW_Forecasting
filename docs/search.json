[
  {
    "objectID": "code/processing/1_initial_cleaning.html",
    "href": "code/processing/1_initial_cleaning.html",
    "title": "Raw data processing",
    "section": "",
    "text": "This script does the following:\n\nLoads raw data files\nChecks for missing data in all raw data files\nConverts qPCR non-detects to NAs\nCalculates LOD and LOQ values for all four assays\nTransforms NAs to LOD for each assay\nBinds all qPCR data sets with WWTP data\nBinds all DPH COVID data"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#info",
    "href": "code/processing/1_initial_cleaning.html#info",
    "title": "Raw data processing",
    "section": "",
    "text": "This script does the following:\n\nLoads raw data files\nChecks for missing data in all raw data files\nConverts qPCR non-detects to NAs\nCalculates LOD and LOQ values for all four assays\nTransforms NAs to LOD for each assay\nBinds all qPCR data sets with WWTP data\nBinds all DPH COVID data"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#load-packages",
    "href": "code/processing/1_initial_cleaning.html#load-packages",
    "title": "Raw data processing",
    "section": "Load packages",
    "text": "Load packages\n\nknitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(here)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stats)"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#load-raw-data",
    "href": "code/processing/1_initial_cleaning.html#load-raw-data",
    "title": "Raw data processing",
    "section": "Load raw data",
    "text": "Load raw data\n\n# Load N1 data\nn1_stepone_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/stepone_n1_FINAL_UPDATE.csv\")) #year 1 data\nn1_cfx_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/cfx_n1_FINAL_UPDATE.csv\")) #year 2 data\n\n# Load N2 data\nn2_stepone_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/stepone_n2_FINAL_UPDATE.csv\")) #year 1 data\nn2_cfx_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/cfx_n2_FINAL_UPDATE.csv\")) #year 2 data\n\n# Load Plant data\nplant_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/plant_data_UPDATED.csv\"))\n\n# Load COVID-19 Symptom data\ncovid_symptom &lt;- read_csv(here(\"data/raw_data/ga_covid_data/epicurve_symptom_date.csv\")) %&gt;% \n  filter(county==\"Clarke\") %&gt;% \n  select(symptom.date=`symptom date`, \n         cases, moving_avg_cases)\n\n#Load COVID-19 Confirmed Case Data\ncovid_case &lt;- read_csv(here(\"data/raw_data/ga_covid_data/epicurve_rpt_date.csv\")) %&gt;% \n  filter(county==\"Clarke\") %&gt;% \n  select(report_date, \n         cases, \n         moving_avg_cases)\n\n#Load COVID-19 Testing Data\ncovid_testing &lt;- read_csv(here(\"data/raw_data/ga_covid_data/pcr_antigen_col.csv\")) %&gt;% \n  filter(county==\"Clarke\") %&gt;% \n  select(collection_date = collection_dt, \n         pcr_tests = `ALL PCR tests performed`, \n         pcr_pos = `All PCR positive tests`, \n         pcr_pos_7dma = `7 day percent positive`,\n         pcr_pos_14dma = `14 day percent positive`)\n\n#Load CFX recovery data\nrecovery_output &lt;- read_csv(here(\"data/raw_data/recovery_data.csv\"))\nrecovery_input &lt;- read_csv(here(\"data/raw_data/calfguard.csv\"))\n\n#Load Hospitalization data\n#hospitalization &lt;- read_csv(here(\"data/raw_data/hospitalizations.csv\"))"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#create-df-to-check-for-missing-collections",
    "href": "code/processing/1_initial_cleaning.html#create-df-to-check-for-missing-collections",
    "title": "Raw data processing",
    "section": "Create df to check for missing collections",
    "text": "Create df to check for missing collections\n\n#Year 1\nnumbers &lt;- 7:92\nnumbers_tbl &lt;- tibble(\"collection_num\"=numbers)\n\n#Year 2\nnumbers2 &lt;- 93:243\nnumbers2_tbl &lt;- tibble(\"collection_num\" =numbers2)\n\n#full time series (for plant data)\nnumbers3 &lt;- 7:243\nnumbers3_tbl &lt;- tibble(\"Collection\" =numbers3)"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#glance-at-data",
    "href": "code/processing/1_initial_cleaning.html#glance-at-data",
    "title": "Raw data processing",
    "section": "Glance at data",
    "text": "Glance at data\n\nStepOne N1\n\nCount observations for each collection number\n\n#count observations for each collection date, then visualize\nn1_stepone_v2 %&gt;% count(collection_num) %&gt;% ggplot(aes(n)) +\n  geom_histogram()\n\n\n\nn1_stepone_v2 %&gt;% ggplot(aes(collection_num)) + \n  geom_histogram(binwidth = 1) #max should be either 27 or 54\n\n\n\n\n\n\nCount observations for each biological replicate\n\n#count observations for each sample id/biological rep, then visualize\nn1_stepone_v2 %&gt;% count(sample_id) %&gt;% ggplot(aes(n)) + \n  geom_histogram() #there should be 3 technical reps\n\n\n\n#check which collections have more than 3 technical reps\nn1_stepone_v2 %&gt;% count(sample_id) %&gt;% filter(n&gt;3)\n\n\n\n  \n\n\n\n\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_n1_stepone &lt;- n1_stepone_v2 %&gt;% count(collection_num) \ncount_n1_stepone &lt;- merge(count_n1_stepone, numbers_tbl, by=\"collection_num\", all.y=T)\n\ncount_n1_stepone\n\n\n\n  \n\n\n#collection 40 is missing, but this is expected\n\n\n\n\nStepOne N2\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_n2_stepone &lt;- n2_stepone_v2 %&gt;% count(collection_num) \ncount_n2_stepone &lt;- merge(count_n2_stepone, numbers_tbl, by=\"collection_num\", all.y=T)\n\ncount_n2_stepone\n\n\n\n  \n\n\n#collection 40 is missing, but this is expected\n\n\n\nCount observations for each collection number\n\n#count observations for each collection date, then visualize\nn2_stepone_v2 %&gt;% count(collection_num) %&gt;% ggplot(aes(n)) +\n  geom_histogram()\n\n\n\nn2_stepone_v2 %&gt;% ggplot(aes(collection_num)) + \n  geom_histogram(binwidth = 1) #max should be either 27 or 54\n\n\n\n\n\n\nCount observations for each biological replicate\n\n#count observations for each sample id/biological rep, then visualize\nn2_stepone_v2 %&gt;% count(sample_id) %&gt;% ggplot(aes(n)) + \n  geom_histogram() #there should be 3 technical reps\n\n\n\n#check which collections have more than 3 technical reps\nn2_stepone_v2 %&gt;% count(sample_id) %&gt;% filter(n&gt;3)\n\n\n\n  \n\n\n\n\n\n\nCFX N1\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_n1_cfx &lt;- n1_cfx_v2 %&gt;% count(collection_num) \ncount_n1_cfx &lt;- merge(count_n1_cfx, numbers2_tbl, by=\"collection_num\", all.y=T)\ncount_n1_cfx\n\n\n\n  \n\n\n\n\n\nCount observations for each collection number\n\n#count observations for each collection date, then visualize\nn1_cfx_v2 %&gt;% count(collection_num) %&gt;% ggplot(aes(n)) +\n  geom_histogram()\n\n\n\nn1_cfx_v2 %&gt;% ggplot(aes(collection_num)) + \n  geom_histogram(binwidth = 1) #max should be 54\n\n\n\n\n\n\nCheck which collections are doubled\n\n#check which collections are doubled\ncount_n1_cfx %&gt;% filter(n==108)\n\n\n\n  \n\n\n\n\n\nCount observations for each biological replicate\n\n#count observations for each sample id/biological rep, then visualize\nn1_cfx_v2 %&gt;% count(sample_id) %&gt;% ggplot(aes(n)) + \n  geom_histogram() #there should be 3 technical reps\n\n\n\n#almost all have 3 replicates, but there is a small amount with 6\n\n#check which collections have more than 3 technical reps\nn1_cfx_v2 %&gt;% count(sample_id) %&gt;% filter(n&gt;3)\n\n\n\n  \n\n\n\n\n\n\nCFX N2\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_n2_cfx &lt;- n2_cfx_v2 %&gt;% count(collection_num) \ncount_n2_cfx &lt;- merge(count_n2_cfx, numbers2_tbl, by=\"collection_num\", all.y=T)\ncount_n2_cfx\n\n\n\n  \n\n\n\n\n\nCheck which collections are doubled\n\n#check which collections are doubled\ncount_n2_cfx %&gt;% filter(n==108)\n\n\n\n  \n\n\n\n\n\nCount observations for each biological replicate\n\n#count observations for each sample id/biological rep, then visualize\nn2_cfx_v2 %&gt;% count(sample_id) %&gt;% ggplot(aes(n)) + \n  geom_histogram() #there should be 3 technical reps\n\n\n\n#almost all have 3 replicates, but there is a small amount with 6 and some with 2\n\n#check which collections have more than 3 technical reps\nn2_cfx_v2 %&gt;% count(sample_id) %&gt;% filter(n&gt;3)\n\n\n\n  \n\n\n\n\n\nCount observations for each collection number\n\n#count observations for each collection date, then visualize\nn2_cfx_v2 %&gt;% count(collection_num) %&gt;% ggplot(aes(n)) +\n  geom_histogram()\n\n\n\nn2_cfx_v2 %&gt;% ggplot(aes(collection_num)) + \n  geom_histogram(binwidth = 1) #max should be 54\n\n\n\n\n\n\n\nPlant data\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_plant &lt;- plant_v2 %&gt;% count(Collection, date) \ncount_plant &lt;- merge(count_plant, numbers3_tbl, by=\"Collection\", all.y=T)\ncount_plant\n\n\n\n  \n\n\n\n\n\nCount observations for each collection date\n\nplant_v2 %&gt;% ggplot(aes(Collection)) + \n  geom_histogram(binwidth = 1) #max should be 3"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#cleaning-and-merging",
    "href": "code/processing/1_initial_cleaning.html#cleaning-and-merging",
    "title": "Raw data processing",
    "section": "Cleaning and merging",
    "text": "Cleaning and merging\n\nqPCR data\n\nSelect for important variables, convert non-detects to NAs\n\n#Select date, collection number, sample id/bio rep, target, and ct\n#Convert Undetermined Cts to NAs\n\n#StepOne N1\nn1_stepone_clean &lt;- n1_stepone_v2 %&gt;% select(c(sample_date, collection_num, sample_id, target, ct)) %&gt;% \n  mutate(ct=as.numeric(ifelse(ct==\"Undetermined\", NA, ct)))\n\n#StepOne N2\nn2_stepone_clean &lt;- n2_stepone_v2 %&gt;% select(c(sample_date, collection_num, sample_id, target, ct)) %&gt;% \n  mutate(ct=as.numeric(ifelse(ct==\"Undetermined\", NA, ct)))\n\n#CFX N1\nn1_cfx_clean &lt;- n1_cfx_v2 %&gt;% select(c(sample_date, collection_num, sample_id, target, ct)) %&gt;% \n  mutate(ct=as.numeric(ifelse(ct==\"Undetermined\", NA, ct)))\n\n#CFX N2\nn2_cfx_clean &lt;- n2_cfx_v2 %&gt;% select(c(sample_date, collection_num, sample_id, target, ct)) %&gt;% \n  mutate(ct=as.numeric(ifelse(ct==\"Undetermined\", NA, ct)))\n\n\n\nBind qPCR NA data sets\n\n#Bind qpcr data\nqpcr_na &lt;- bind_rows(n1_stepone_clean, n2_stepone_clean, n1_cfx_clean, n2_cfx_clean) %&gt;% \n  mutate(\n    date = sample_date,\n    facility=substr(sample_id, 1,2), #first two letters in sample_id is treatment facility ID\n    biological_replicate=substr(sample_id, nchar(sample_id), nchar(sample_id))) %&gt;% #last number in sample_id is the biological rep\n arrange(date, facility, target, biological_replicate) %&gt;% \n  select(date, facility, target, biological_replicate, collection_num, ct)#select necessary variables\n  \n#Save to processed data folder\nsaveRDS(qpcr_na, here(\"data/processed_data/qpcr_na.rds\"))\n\n\n\nCalculate LOD and LOQ for qPCR data\n\n#Determine the LOD and LOQ by plotting the Normal QQ-Plot\n#Code generated by Cody Daley and Megan Lott?\nqqnorm.ct.n1.stepone &lt;- qqnorm(n1_stepone_clean$ct, plot.it = F) %&gt;% as.data.frame()\nqqnorm.ct.n2.stepone &lt;- qqnorm(n2_stepone_clean$ct, plot.it = F) %&gt;% as.data.frame()\nqqnorm.ct.n1.cfx &lt;- qqnorm(n1_cfx_clean$ct, plot.it = F) %&gt;% as.data.frame()\nqqnorm.ct.n2.cfx &lt;- qqnorm(n2_cfx_clean$ct, plot.it = F) %&gt;% as.data.frame()\n\n#Create function to compute LOD and lOQ\nqqnorm.Explorer.ct &lt;- function(qqnorm.ct){\n  qqnorm.ct &lt;- qqnorm.ct[which(complete.cases(qqnorm.ct)),]\n  qqnorm.ct &lt;- qqnorm.ct[order(qqnorm.ct$x),]\n  qqnorm.ct &lt;- cbind(qqnorm.ct, rbind(NA, qqnorm.ct[-nrow(qqnorm.ct),])) %&gt;% setNames(., nm = c(\"x\", \"y\", \"x-1\", \"y-1\"))\n  qqnorm.ct %&lt;&gt;% mutate(rise = y-`y-1`, run = x-`x-1`) %&gt;% mutate(slope = rise / run)\n  qqnorm.ct$lod &lt;- NA\n  qqnorm.ct$loq &lt;- NA\n  prev.slope &lt;- 1\n  lod.found &lt;- 0\n  for(i in nrow(qqnorm.ct):2){\n    if(lod.found==0){\n      if(qqnorm.ct$slope[i]&lt;1 & prev.slope &lt;1){\n        qqnorm.ct$lod[i] &lt;- 1\n        lod.found &lt;- 1\n      }else{\n        prev.slope &lt;- qqnorm.ct$slope[i]\n      }\n    }\n    if(lod.found==1){\n      if(qqnorm.ct$slope[i]&gt;1){\n        qqnorm.ct$loq[i] &lt;- 1\n        break\n      }else{\n        prev.slope &lt;- qqnorm.ct$slope[i]\n      }\n    }\n  }\n  lod.ct &lt;- qqnorm.ct$y[which(qqnorm.ct$lod==1)]\n  loq.ct &lt;- qqnorm.ct$y[which(qqnorm.ct$loq==1)]\n  return(list(qqnorm.dataset = qqnorm.ct, lod = lod.ct, loq = loq.ct))\n}\n\n#Run function on each data set\nqqnorm.ct.n1.stepone &lt;- qqnorm.Explorer.ct(qqnorm.ct.n1.stepone)\nqqnorm.ct.n2.stepone &lt;- qqnorm.Explorer.ct(qqnorm.ct.n2.stepone)\nqqnorm.ct.n1.cfx &lt;- qqnorm.Explorer.ct(qqnorm.ct.n1.cfx)\nqqnorm.ct.n2.cfx &lt;- qqnorm.Explorer.ct(qqnorm.ct.n2.cfx)\n\n#Save LOD and LOQ for each data set\nn1_stepone_lod &lt;- qqnorm.ct.n1.stepone$lod\nn1_stepone_loq &lt;- qqnorm.ct.n1.stepone$loq\nn2_stepone_lod &lt;- qqnorm.ct.n2.stepone$lod\nn2_stepone_loq &lt;- qqnorm.ct.n2.stepone$loq\n\nn1_cfx_lod &lt;- qqnorm.ct.n1.cfx$lod\nn1_cfx_loq &lt;- qqnorm.ct.n1.cfx$loq\nn2_cfx_lod &lt;- qqnorm.ct.n2.cfx$lod\nn2_cfx_loq &lt;- qqnorm.ct.n2.cfx$loq\n\nsaveRDS(n1_stepone_lod, here(\"data/processed_data/n1_stepone_lod.rds\"))  \nsaveRDS(n2_stepone_lod, here(\"data/processed_data/n2_stepone_lod.rds\"))\nsaveRDS(n1_cfx_lod, here(\"data/processed_data/n1_cfx_lod.rds\"))\nsaveRDS(n2_cfx_lod, here(\"data/processed_data/n2_cfx_lod.rds\"))\n\n\n\nTransform Ct NAs to calculate SARS-CoV-2 copies\n\nUsing LOD\n\n#Replace NAs with limit of detection\n#Use standard curve slope for each target to calculate copies per uL per rxn\n\n#StepOne N1\nn1_stepone_1 &lt;- n1_stepone_clean %&gt;% \n  mutate(ct = replace_na(ct, n1_stepone_lod),\n         copy_num_uL_rxn = as.numeric(10^((ct-34.008)/-3.389)))\n\n#StepOne N2\nn2_stepone_1 &lt;- n2_stepone_clean %&gt;% \n  mutate(ct = replace_na(ct, n2_stepone_lod),\n         copy_num_uL_rxn = as.numeric(10^((ct-32.416)/-3.3084)))\n\n#CFX N1\nn1_cfx_1 &lt;- n1_cfx_clean %&gt;% \n  mutate(ct = replace_na(ct, n1_cfx_lod), \n         copy_num_uL_rxn = as.numeric(10^((ct-36.046)/-3.5293)))\n\n#CFX N2\nn2_cfx_1 &lt;- n2_cfx_clean %&gt;% \n  mutate(ct = replace_na(ct, n2_cfx_lod),\n         copy_num_uL_rxn = as.numeric(10^((ct-37.731)/-3.2505)))\n\n\n#N1 StepOne\nn1_stepone_1 %&gt;% filter(ct&lt;n1_stepone_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N2 StepOne\nn2_stepone_1 %&gt;% filter(ct&lt;n2_stepone_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N1 CFX\nn1_cfx_1 %&gt;% filter(ct&lt;n1_cfx_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N2 CFX\nn2_cfx_1 %&gt;% filter(ct&lt;n2_cfx_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#loooooots of non-detects in first year of surveillance, makes sense because it was early in the pandemic\n\n\n\nUsing Ct 40\n\n#Replace NAs with limit of detection\n#Use standard curve slope for each target to calculate copies per uL per rxn\n\n#StepOne N1\nn1_stepone_2 &lt;- n1_stepone_clean %&gt;% \n  mutate(ct = replace_na(ct, 40),\n         copy_num_uL_rxn = as.numeric(10^((ct-34.008)/-3.389)))\n\n#StepOne N2\nn2_stepone_2 &lt;- n2_stepone_clean %&gt;% \n  mutate(ct = replace_na(ct, 40),\n         copy_num_uL_rxn = as.numeric(10^((ct-32.416)/-3.3084)))\n\n#CFX N1\nn1_cfx_2 &lt;- n1_cfx_clean %&gt;% \n  mutate(ct = replace_na(ct, 40), \n         copy_num_uL_rxn = as.numeric(10^((ct-36.046)/-3.5293)))\n\n#CFX N2\nn2_cfx_2 &lt;- n2_cfx_clean %&gt;% \n  mutate(ct = replace_na(ct, 40),\n         copy_num_uL_rxn = as.numeric(10^((ct-37.731)/-3.2505)))\n\n\n#N1 StepOne\nn1_stepone_2 %&gt;% filter(ct&lt;n1_stepone_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N2 StepOne\nn2_stepone_2 %&gt;% filter(ct&lt;n2_stepone_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N1 CFX\nn1_cfx_2 %&gt;% filter(ct&lt;n1_cfx_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N2 CFX\nn2_cfx_2 %&gt;% filter(ct&lt;n2_cfx_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#loooooots of non-detects\n\n\n\nUsing ct 42\n\n#Replace NAs with limit of detection\n#Use standard curve slope for each target to calculate copies per uL per rxn\n\n#StepOne N1\nn1_stepone_3 &lt;- n1_stepone_clean %&gt;% \n  mutate(ct = replace_na(ct, 42),\n         copy_num_uL_rxn = as.numeric(10^((ct-34.008)/-3.389)))\n\n#StepOne N2\nn2_stepone_3 &lt;- n2_stepone_clean %&gt;% \n  mutate(ct = replace_na(ct, 42),\n         copy_num_uL_rxn = as.numeric(10^((ct-32.416)/-3.3084)))\n\n#CFX N1\nn1_cfx_3 &lt;- n1_cfx_clean %&gt;% \n  mutate(ct = replace_na(ct, 42), \n         copy_num_uL_rxn = as.numeric(10^((ct-36.046)/-3.5293)))\n\n#CFX N2\nn2_cfx_3 &lt;- n2_cfx_clean %&gt;% \n  mutate(ct = replace_na(ct, 42),\n         copy_num_uL_rxn = as.numeric(10^((ct-37.731)/-3.2505)))\n\n\n\n\nQuick look at Ct distribution\n\n#N1 StepOne\nn1_stepone_3 %&gt;% filter(ct&lt;n1_stepone_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N2 StepOne\nn2_stepone_3 %&gt;% filter(ct&lt;n2_stepone_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N1 CFX\nn1_cfx_3 %&gt;% filter(ct&lt;n1_cfx_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N2 CFX\nn2_cfx_3 %&gt;% filter(ct&lt;n2_cfx_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#loooooots of non-detects\n\n\n\nBind all qPCR data sets\n\n#Bind qpcr data\nqpcr_all &lt;- bind_rows(n1_stepone_1, n2_stepone_1, n1_cfx_1, n2_cfx_1) %&gt;% \n  mutate(\n    date = sample_date,\n    facility=substr(sample_id, 1,2), #first two letters in sample_id is treatment facility ID\n    biological_replicate=substr(sample_id, nchar(sample_id), nchar(sample_id))) %&gt;% #last number in sample_id is the biological rep\n arrange(date, facility, target, biological_replicate) %&gt;% \n  select(date, facility, target, biological_replicate, collection_num, ct, copy_num_uL_rxn)#select necessary variables\n  \n#Save to processed data folder\nsaveRDS(qpcr_all, here(\"data/processed_data/qpcr_all1.rds\"))\nqpcr_all\n\n\n\n  \n\n\n\n\nqpcr_all_2 &lt;- bind_rows(n1_stepone_2, n2_stepone_2, n1_cfx_2, n2_cfx_2) %&gt;% \n  mutate(\n    date = sample_date,\n    facility=substr(sample_id, 1,2), #first two letters in sample_id is treatment facility ID\n    biological_replicate=substr(sample_id, nchar(sample_id), nchar(sample_id))) %&gt;% #last number in sample_id is the biological rep\n arrange(date, facility, target, biological_replicate) %&gt;% \n  select(date, facility, target, biological_replicate, collection_num, ct, copy_num_uL_rxn)#select necessary variables\n  \n#Save to processed data folder\nsaveRDS(qpcr_all, here(\"data/processed_data/qpcr_all2.rds\"))\nqpcr_all_2\n\n\n\n  \n\n\n\n\nqpcr_all_3 &lt;- bind_rows(n1_stepone_3, n2_stepone_3, n1_cfx_3, n2_cfx_3) %&gt;% \n  mutate(\n    date = sample_date,\n    facility=substr(sample_id, 1,2), #first two letters in sample_id is treatment facility ID\n    biological_replicate=substr(sample_id, nchar(sample_id), nchar(sample_id))) %&gt;% #last number in sample_id is the biological rep\n arrange(date, facility, target, biological_replicate) %&gt;% \n  select(date, facility, target, biological_replicate, collection_num, ct, copy_num_uL_rxn)#select necessary variables\n  \n#Save to processed data folder\nsaveRDS(qpcr_all, here(\"data/processed_data/qpcr_all3.rds\"))\nqpcr_all_3\n\n\n\n  \n\n\n\n\n\n\nCombine plant and qPCR data sets\n\n#Change plant variable names to match qPCR names, remove notes variable, convert millions of gallons to liters\nplant_v2&lt;- plant_v2 %&gt;% rename(collection_num = Collection, facility = wrf) %&gt;% \n  select(!notes) %&gt;% \n  mutate(influent_flow_L = influent_flow_mg*1e6*231*(0.0254^3)*1000)\n\n#Select qPCR variables to merge\n#qpcr_all &lt;- qpcr_all %&gt;% select(!date)\n\n#Merge and mutate\nqpcr_plant_all &lt;- merge(qpcr_all, plant_v2, by = c(\"collection_num\", \"facility\", \"date\"), all = T) %&gt;% \n  mutate(facility = as.factor(facility), #code each facility as a factor\n         facility = recode(facility, NO = \"A\", MI = \"B\", CC = \"C\"), #de-identify treatment facility\n         facility = ordered(facility, levels = c(\"A\", \"B\", \"C\")), #set facility factor levels\n         copy_num_L = copy_num_uL_rxn*20/5*60/280*1000*1000,\n         viral_load = copy_num_L*influent_flow_L) #transform copies per uL of reaction to copies per liter\n\n#Save to processed data folder\nsaveRDS(qpcr_plant_all, here(\"data/processed_data/qpcr_plant_all.rds\"))\n\n\n\nQuick look at WBE data\n\n#Filter for correct date range, then visualize observations for each collection\nqpcr_plant_all %&gt;% filter(between(collection_num, 7, 243)) %&gt;% \n  ggplot(aes(collection_num)) +\n  geom_bar()\n\n\n\n\n\n#which observations are low?\nqpcr_plant_all %&gt;% count(collection_num) %&gt;% \n  filter(between(collection_num, 7, 243), n &lt; 10)\n\n\n\n  \n\n\n\n\n\nCombine DPH COVID data sets\n\ncovid &lt;- full_join(\n  covid_symptom%&gt;%\n    select(cases.symptom.onset=cases, date=symptom.date), \n  covid_case%&gt;%\n    select(cases.reported=cases, date=report_date), \n  by = \"date\"\n) %&gt;% \n  full_join(\n    covid_testing%&gt;%\n      rename(date=collection_date), \n    by=\"date\"\n  ) %&gt;%\n  select(date, cases.symptom.onset, cases.reported, pcr_tests, pcr_pos, pcr_pos_7dma, pcr_pos_14dma) %&gt;% \n\n  mutate(prop_pos = pcr_pos/pcr_tests)\n\n#Save to processed data folder\nsaveRDS(covid, here(\"data/processed_data/all_covid_combined.rds\"))\ncovid"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#filter-hospitalization-data",
    "href": "code/processing/1_initial_cleaning.html#filter-hospitalization-data",
    "title": "Raw data processing",
    "section": "Filter hospitalization data",
    "text": "Filter hospitalization data\nFilter for state of GA, city of Athens, and for appropriate dates\n\n#athens_hospitalizations &lt;- hospitalization %&gt;% \n  #filter(state==\"GA\", city==\"ATHENS\", between(collection_week, as.Date(\"2020-06-28\"), as.Date(\"2023-01-08\")))\n\n#Save to processed data folder\n#saveRDS(athens_hospitalizations, here(\"data/processed_data/athens_hospitalizations.rds\"))\n\n\nCombine WBE and COVID data sets\n\nwbe_covid &lt;- merge(qpcr_plant_all, covid, by = \"date\", all = T) %&gt;% \n  filter(between(date, as.Date(\"2020-06-30\"), as.Date(\"2021-06-30\")))\n\nwbe_covid\n\n\n\n  \n\n\n#I didn't save this because I probably won't use it, we can combine later in script 2"
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me!",
    "section": "",
    "text": "University of Georgia Environmental Health Science\n\n\n\nErin Lipp\nTravis Glenn\n\n\n\nAndreas Handel"
  },
  {
    "objectID": "code/processing/2_preprocessing.html",
    "href": "code/processing/2_preprocessing.html",
    "title": "Pre-processing",
    "section": "",
    "text": "This pre-processing script does the following:\n\nWBE technical replicates are averaged\nViral load is summed across WWTPs per date per target\nViral load is averaged across targets (N1 and N2) per date\nWW qPCR assay detection frequency is calculated\n7 day moving average is calculated for all variables of interest\nWBE and COVID data are combined and weekly averages are calculated\nHospitalization data will also be added in the future"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#info",
    "href": "code/processing/2_preprocessing.html#info",
    "title": "Pre-processing",
    "section": "",
    "text": "This pre-processing script does the following:\n\nWBE technical replicates are averaged\nViral load is summed across WWTPs per date per target\nViral load is averaged across targets (N1 and N2) per date\nWW qPCR assay detection frequency is calculated\n7 day moving average is calculated for all variables of interest\nWBE and COVID data are combined and weekly averages are calculated\nHospitalization data will also be added in the future"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#load-packages",
    "href": "code/processing/2_preprocessing.html#load-packages",
    "title": "Pre-processing",
    "section": "Load packages",
    "text": "Load packages\n\nknitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fpp3)\nlibrary(skimr)\nlibrary(ggpubr)"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#load-data",
    "href": "code/processing/2_preprocessing.html#load-data",
    "title": "Pre-processing",
    "section": "Load data",
    "text": "Load data\n\n#WBE file from processing script\nwbe &lt;- read_rds(here(\"data/processed_data/qpcr_plant_all.rds\"))\n\n#COVID file from processing script\ncovid &lt;- read_rds(here(\"data/processed_data/all_covid_combined.rds\"))\n\n#Hospitalization data from processing script\nhospital &lt;- read_rds(here(\"data/processed_data/athens_hospitalizations.rds\"))\n\n#Load qPCR file with ct NAs from processing script\nqpcr_na &lt;- read_rds(here(\"data/processed_data/qpcr_na.rds\"))"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#a-wbe-wrangling",
    "href": "code/processing/2_preprocessing.html#a-wbe-wrangling",
    "title": "Pre-processing",
    "section": "A) WBE Wrangling",
    "text": "A) WBE Wrangling\n\n1. More cleaning\n\n#Remove observations when Cts = NA, this means that collection is missing or not part of the surveillance study\nwbe &lt;- wbe %&gt;% na.omit(ct)\n\n#Check for NAs in the rest of the data\nskim(wbe) #yay nothing is missing\n\n\nData summary\n\n\nName\nwbe\n\n\nNumber of rows\n20556\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nDate\n1\n\n\nfactor\n1\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntarget\n0\n1\n2\n2\n0\n2\n0\n\n\nbiological_replicate\n0\n1\n1\n1\n0\n7\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n2020-06-30\n2023-01-04\n2021-12-20\n230\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nfacility\n0\n1\nTRUE\n3\nA: 6893, B: 6872, C: 6791\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncollection_num\n0\n1\n1.378800e+02\n6.259000e+01\n7.000000e+00\n8.900000e+01\n1.400000e+02\n1.910000e+02\n2.430000e+02\n▃▇▇▇▇\n\n\nct\n0\n1\n3.807000e+01\n1.500000e+00\n3.102000e+01\n3.711000e+01\n3.766000e+01\n3.994000e+01\n4.000000e+01\n▁▁▂▇▇\n\n\ncopy_num_uL_rxn\n0\n1\n4.300000e-01\n8.700000e-01\n1.000000e-02\n1.200000e-01\n2.000000e-01\n5.200000e-01\n3.485000e+01\n▇▁▁▁▁\n\n\ninfluent_flow_mg\n0\n1\n3.690000e+00\n1.770000e+00\n1.280000e+00\n1.830000e+00\n3.550000e+00\n5.180000e+00\n1.311000e+01\n▇▆▁▁▁\n\n\ninfluent_tss_mg_l\n0\n1\n2.474500e+02\n1.690100e+02\n4.800000e+00\n1.480000e+02\n2.080000e+02\n2.840000e+02\n1.380000e+03\n▇▂▁▁▁\n\n\ninfluent_flow_L\n0\n1\n1.398262e+07\n6.684690e+06\n4.845327e+06\n6.927304e+06\n1.343821e+07\n1.960843e+07\n4.962675e+07\n▇▆▁▁▁\n\n\ncopy_num_L\n0\n1\n3.697209e+05\n7.458327e+05\n8.616570e+03\n1.020177e+05\n1.725005e+05\n4.451149e+05\n2.987138e+07\n▇▁▁▁▁\n\n\nviral_load\n0\n1\n4.923052e+12\n9.907915e+12\n8.344504e+10\n1.031717e+12\n2.331721e+12\n5.253990e+12\n3.595800e+14\n▇▁▁▁▁\n\n\n\n\n#Count observations for each date/facility/target/collection\nwbe_count &lt;- wbe %&gt;% count(date,facility,target,collection_num) #max is either 9 or 18\nhead(wbe_count, n = 10)\n\n\n\n  \n\n\n\n\n\n2. Average qPCR replicates\n\n#group, then take the average copies per liter and standard deviation\nwbe_avg &lt;- wbe %&gt;% \n  group_by(date,facility,target,collection_num) %&gt;% \n  summarize(avg_copy_L = mean(copy_num_L),\n            sd_copy_L = sd(copy_num_L), \n            influent_flow_L = mean(influent_flow_L),\n            avg_viral_load = mean(viral_load),\n            sd_viral_load = sd(viral_load),\n            avg_ct = mean(ct),\n            sd_ct = sd(ct))%&gt;% \n  ungroup()\nhead(wbe_avg, n=10)\n\n\n\n  \n\n\n\n\n\n3. Sum Viral Load across WWTPs\n\nwbe_county_avg &lt;- wbe_avg %&gt;% \n  group_by(date, collection_num, target) %&gt;% \n  summarize(viral_load = sum(avg_viral_load)) %&gt;% #sum across WWTPs for each target\n  ungroup()\n\nhead(wbe_county_avg, n=10)\n\n\n\n  \n\n\n\n\n\n4. Move N1 and N2 to distinct columns, then calculate average\n\navg_viral_load &lt;- wbe_county_avg %&gt;% \n  group_by(date) %&gt;% \n  summarize(avg_vl = mean(viral_load))\n\nwbe_vl_final &lt;- wbe_county_avg %&gt;% \n  pivot_wider(names_from = target, values_from = viral_load) %&gt;% \n  rename(n1_vl = N1, n2_vl = N2)\n\nwbe_vl_final &lt;- wbe_vl_final %&gt;% full_join(avg_viral_load, wbe_final, by = \"date\")\nhead(wbe_vl_final, n=10)\n\n\n\n  \n\n\n\n\n\n5. Calculate qPCR % Pos\nTechnical replicates per bio rep/target/facility/date\n\ndetection_tr &lt;- qpcr_na %&gt;% \n  select(c(date,facility,target,biological_replicate,ct)) %&gt;% \n        group_by(date,facility,target,biological_replicate) %&gt;% \n        summarize(n = n(), \n                  n_miss = sum(is.na(ct)),\n                  n_pos = n-n_miss)\nhead(detection_tr,n=10)\n\n\n\n  \n\n\n\nTechnical reps per target/facility/date\n\ndetection_target &lt;- qpcr_na %&gt;% \n  select(c(date,facility,target,biological_replicate,ct)) %&gt;% \n        group_by(date,facility,target) %&gt;% \n        summarize(n = n(), \n                  n_miss = sum(is.na(ct)),\n                  n_pos = n-n_miss,\n                  pos_rate = (n_pos/n)*100) %&gt;% \n  ungroup()\n\ndetection_target_wide &lt;- detection_target %&gt;% pivot_wider(names_from = target, values_from = c(n, n_miss, n_pos, pos_rate))\n\nhead(detection_target_wide, n=10)\n\n\n\n  \n\n\n\nTechnical reps per facility/date\n\ndetection_facility &lt;- qpcr_na %&gt;% \n  select(c(date,facility,target,biological_replicate,ct)) %&gt;% \n        group_by(date,facility) %&gt;% \n        summarize(n = n(), \n                  n_miss = sum(is.na(ct)),\n                  n_pos = n-n_miss,\n                  pos_rate = (n_pos/n)*100)\n\nhead(detection_facility, n=10)\n\n\n\n  \n\n\n\nTechnical reps per date (targets included)\n\ndetection_date &lt;- qpcr_na %&gt;% \n  select(c(date,facility,target,biological_replicate,ct)) %&gt;% \n        group_by(date,target) %&gt;% #summarize at county level for both targets\n        summarize(n_reps = n(), #count number of technical reps\n                  n_miss = sum(is.na(ct)), #count number of non detects\n                  n_pos = n_reps-n_miss, #count number of detects\n                  pos_rate = (n_pos/n_reps)*100) %&gt;% #calculate detection frequency\n  ungroup() %&gt;% \n  pivot_wider(names_from = target, values_from=c(n_reps, pos_rate, n_miss, n_pos)) %&gt;%\n  #put N1 and N2 in separate columns\n  mutate(n_reps=n_reps_N1+n_reps_N2, #add reps from both targets\n         n_miss=n_miss_N1+n_miss_N2, #add nondetects from both targets\n         n_pos=n_reps-n_miss, #add detects from both targets\n         avg_pos_rate = (n_pos/n_reps)*100) %&gt;% #average detection freq across targets\n  select(!c(n_pos,n_miss,n_pos_N1,n_miss_N1,n_pos_N2,n_miss_N2)) #dump these\n\nhead(detection_date,n=10)\n\n\n\n  \n\n\n\n\n\n6. Smoosh wbe data set with %pos data\n\nwbe_daily &lt;- left_join(wbe_vl_final,detection_date, by=\"date\") %&gt;% \n  mutate(week = yearweek(date))\n\nhead(wbe_daily,n=10)\n\n\n\n  \n\n\nsaveRDS(wbe_daily,here(\"data/processed_data/wbe_county_avg.rds\"))\n\n\n\n7. Calculate WBE 7-DMA\n\nwbe_7dma &lt;- wbe_daily %&gt;% mutate(\n  vl_7dma=stats::filter(avg_vl,filter=rep(1/7,7),method= 'convolution',sides=1),\n  vl_n1_7dma=stats::filter(n1_vl,filter=rep(1/7,7),method= 'convolution',sides=1),\n  vl_n2_7dma=stats::filter(n2_vl,filter=rep(1/7,7),method= 'convolution',sides=1),\n  pr_7dma=stats::filter(avg_pos_rate,filter=rep(1/7,7),method= 'convolution',sides=1),\n  pr_n1_7dma=stats::filter(pos_rate_N1,filter=rep(1/7,7),method= 'convolution',sides=1),\n  pr_n2_7dma=stats::filter(pos_rate_N2,filter=rep(1/7,7),method= 'convolution',sides=1))\nhead(wbe_7dma, n=10)\n\n\n\n  \n\n\nsaveRDS(wbe_7dma,here(\"data/processed_data/wbe_7dma.rds\"))"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#b-covid-wrangling",
    "href": "code/processing/2_preprocessing.html#b-covid-wrangling",
    "title": "Pre-processing",
    "section": "B) COVID Wrangling",
    "text": "B) COVID Wrangling\n\n1. Subset COVID dates\n\ncovid_daily &lt;- covid %&gt;% \n  filter(between(date, as.Date(\"2020-06-30\"), as.Date(\"2023-01-04\"))) %&gt;%  #filter for surveillance time series\n  mutate(date = as_date(date),\n         week = yearweek(date))\n\nhead(covid_daily,n=10)\n\n\n\n  \n\n\n\n\n\n2. Calculate Case 7-DMA\n\ncovid_7dma &lt;- covid_daily %&gt;% mutate(\n symptom_onset_7dma=stats::filter(cases.symptom.onset,filter=rep(1/7,7),method= 'convolution',sides=1),\n case_report_7dma=stats::filter(cases.reported,filter=rep(1/7,7),method= 'convolution',sides=1),\n case_pcr_pos_7dma=stats::filter(pcr_pos,filter=rep(1/7,7),method= 'convolution',sides=2),\n case_prop_pos_7dma=stats::filter(prop_pos,filter=rep(1/7,7),method= 'convolution',sides=1))\n\nhead(covid_7dma,n=10)\n\n\n\n  \n\n\nsaveRDS(covid_7dma,here(\"data/processed_data/covid_7dma.rds\"))"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#c-combine-wbe-covid",
    "href": "code/processing/2_preprocessing.html#c-combine-wbe-covid",
    "title": "Pre-processing",
    "section": "C) Combine WBE & COVID",
    "text": "C) Combine WBE & COVID\n\ncovid_wbe_7dma &lt;- left_join(wbe_7dma, covid_7dma, by = c(\"week\",\"date\"))\ncovid_wbe_7dma_weekly &lt;- covid_wbe_7dma %&gt;% \nselect(c(date,week,n1_vl,n2_vl,avg_vl,vl_n1_7dma,vl_n2_7dma,vl_7dma,\n          n_reps_N1,n_reps_N2,n_reps,pos_rate_N1,pos_rate_N2,avg_pos_rate,\n          pr_n1_7dma,pr_n2_7dma,pr_7dma,\n          cases.symptom.onset,symptom_onset_7dma,cases.reported,case_report_7dma,\n          pcr_tests,pcr_pos,pcr_pos_7dma,case_pcr_pos_7dma,pcr_pos_14dma,\n          prop_pos, case_prop_pos_7dma)) %&gt;% \n  group_by(week) %&gt;% \n  summarize_if(is.numeric, mean, na.rm = TRUE) %&gt;% \n  ungroup() %&gt;% \n  as_tsibble(index = \"week\")\n\nhead(covid_wbe_7dma_weekly,n=10)\n\n\n\n  \n\n\nsaveRDS(covid_wbe_7dma_weekly,here(\"data/processed_data/covid_wbe_7dma_weekly.rds\"))"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html",
    "href": "code/analysis/3_exploratory_timeseries.html",
    "title": "Exploratory - Time series",
    "section": "",
    "text": "knitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fpp3)\nlibrary(ggthemes)"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html#load-packages",
    "href": "code/analysis/3_exploratory_timeseries.html#load-packages",
    "title": "Exploratory - Time series",
    "section": "",
    "text": "knitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fpp3)\nlibrary(ggthemes)"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html#load-data",
    "href": "code/analysis/3_exploratory_timeseries.html#load-data",
    "title": "Exploratory - Time series",
    "section": "Load data",
    "text": "Load data\n\ndata &lt;- readRDS(here(\"data/processed_data/covid_wbe_7dma_weekly.rds\"))\n#from pre_processing script\n\ndata"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html#look-at-time-series",
    "href": "code/analysis/3_exploratory_timeseries.html#look-at-time-series",
    "title": "Exploratory - Time series",
    "section": "Look at time series",
    "text": "Look at time series\n\n1. Viral Load\n\ndata %&gt;% na.omit() %&gt;% \n  ggplot(aes(x=week)) +\n  geom_line(aes(y=log10(vl_7dma),color=\"VL 7DMA\")) +\n  geom_line(aes(y=log10(avg_vl),color=\"VL\")) +\n  theme_bw() +\n  labs(title = \"Viral Load vs Viral Load 7DMA\") +\n  ylab(\"Log10 Weekly Average Copies per Day\")\n\n\n\n\n\n\n2. qPCR positivity rate\n\ndata %&gt;% na.omit() %&gt;% \n  ggplot(aes(x=week)) +\n  geom_line(aes(y=avg_pos_rate,color=\"WW PR\")) +\n  geom_line(aes(y=pr_7dma,color=\"WW PR 7DMA\")) +\n  theme_bw() +\n  labs(title = \"Wastewater Pos Rate vs Wastewater Pos Rate 7DMA\") +\n  ylab(\"Weekly Average Percent Positive qPCR Reactions\")\n\n\n\n\n\n\n3. Case symptom onset\n\ndata %&gt;% na.omit() %&gt;% \n  ggplot(aes(x=week)) +\n  geom_line(aes(y=cases.symptom.onset,color=\"Symptom onset\")) +\n  geom_line(aes(y=symptom_onset_7dma,color=\"Symptom onset 7DMA\")) +\n  theme_bw() +\n  labs(title = \"Symptom Onset vs Symptom Onset 7DMA\") +\n  ylab(\"Weekly Average Case Symptom Onset\")\n\n\n\n\n\n\n4. Cases reported\n\ndata %&gt;% na.omit() %&gt;% \n  ggplot(aes(x=week)) +\n  geom_line(aes(y=cases.reported,color=\"Cases reported\")) +\n  geom_line(aes(y=case_report_7dma,color=\"Cases reported 7DMA\")) +\n  theme_bw() +\n  labs(title = \"Cases Reported vs Cases Reported 7DMA\") +\n  ylab(\"Weekly Average Cases Reported\")\n\n\n\n\n\n\n5. Case test positives\n\ndata %&gt;% na.omit() %&gt;% \n  ggplot(aes(x=week)) +\n  geom_line(aes(y=pcr_pos,color=\"Pos clinical tests\")) +\n  geom_line(aes(y=case_pcr_pos_7dma,color=\"Pos clinical tests 7DMA\")) +\n  geom_line(aes(y=pcr_pos_7dma,color=\"7DMA calculated by DPH\")) +\n  theme_bw() +\n  labs(title = \"Positive Clinical Tests vs Positive Clinical Test 7DMA\") +\n  ylab(\"Weekly Average Positive PCR Tests\")\n\n\n\n\n\n\n6. Case test positivity rate\n\ndata %&gt;% na.omit() %&gt;% \n  ggplot(aes(x=week)) +\n  geom_line(aes(y=prop_pos*100,color=\"Clinical Test PR\")) +\n  geom_line(aes(y=case_prop_pos_7dma,color=\"Clinical Test PR 7DMA\")) +\n  theme_bw() +\n  labs(title = \"Clinical Positivity Rate vs Clinical Positivity Rate 7DMA\") +\n  ylab(\"Weekly Average Percent Positive PCR Tests\")\n\n\n\n\n\n\n9. Clinical test admin\n\ndata %&gt;% na.omit() %&gt;% \n  ggplot(aes(week, pcr_tests)) +\n  geom_line() +\n  theme_bw() +\n  labs(title = \"Clinical Tests Administered Over Time\") +\n  ylab(\"Weekly Average Clinical Tests\")"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html#notes",
    "href": "code/analysis/3_exploratory_timeseries.html#notes",
    "title": "Exploratory - Time series",
    "section": "Notes",
    "text": "Notes\n\nall time series follow roughly the same trend\npeaks happen roughly twice per year, the first during the fall (Aug-Oct, potentially influenced by student population influx) and second during the winter (Dec-Feb)\ntests reported, in general, peak during peak transmission times, but that trend does not continue past the beginning of 2022 (see 9. Test admin), indicating the shift to at-home testing and subsequent under-reporting\nit may make sense to split at March-April 2022 as correlations between wastewater metrics and case metrics could weaken past this point"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Data Repository",
    "section": "",
    "text": "Purpose\nPhD Chapter 1 data repository\nExploring COVID-19 forecasting methods using wastewater surveillance data\n\n\nScripts\n\nFor data legends and other info, see the Read Me file\n\nInitial Data Cleaning\nData Preprocessing\nExploratory Time Series Analysis\nUnivariate Linear Regressions"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html",
    "href": "code/analysis/4_univariate_regressions.html",
    "title": "Univariate Linear Regressions",
    "section": "",
    "text": "knitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(forecast)\nlibrary(tidymodels)"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#load-packages",
    "href": "code/analysis/4_univariate_regressions.html#load-packages",
    "title": "Univariate Linear Regressions",
    "section": "",
    "text": "knitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(forecast)\nlibrary(tidymodels)"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#load-data",
    "href": "code/analysis/4_univariate_regressions.html#load-data",
    "title": "Univariate Linear Regressions",
    "section": "Load data",
    "text": "Load data\n\ndata &lt;- readRDS(here(\"data/processed_data/covid_wbe_7dma_weekly.rds\")) %&gt;% \n  mutate(log10_vl_7dma=log10(vl_7dma),\n         log_case_pos_7dma=log(case_pcr_pos_7dma),\n         case_prop_pos_7dma=case_prop_pos_7dma*100,\n         log_case_prop_pos_7dma=log(case_prop_pos_7dma),\n         log_pr_7dma=log(pr_7dma))\n\n#certain variables have been transformed due to distribution abnormality, with some distributions being normalized by certain transformations\n\n#i wanted to build models with both transformed and non-transformed data to compare performances\n\ndata"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#data-splitting",
    "href": "code/analysis/4_univariate_regressions.html#data-splitting",
    "title": "Univariate Linear Regressions",
    "section": "Data splitting",
    "text": "Data splitting\nSee notes on script 3 for details\n\ndata_train_dates &lt;- data %&gt;% head(n = 92) #selects dates before or on the 13th week of 2022 (end of March)\nsplit &lt;- initial_split(data_train_dates, prop=8/10) #reserve 20% of observations at random to do validation\nset.seed(13)\ntrain &lt;- training(split) #create dataset to train models with\n\nset.seed(16)\ntest &lt;- testing(split) #create smaller dataset to do model performance validation with"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#define-model",
    "href": "code/analysis/4_univariate_regressions.html#define-model",
    "title": "Univariate Linear Regressions",
    "section": "Define model",
    "text": "Define model\n\nlr &lt;- linear_reg()\nnull &lt;- null_model() %&gt;% set_engine(\"parsnip\") %&gt;% set_mode(\"regression\")"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#a-log10-viral-load-as-predictor",
    "href": "code/analysis/4_univariate_regressions.html#a-log10-viral-load-as-predictor",
    "title": "Univariate Linear Regressions",
    "section": "A) Log10 Viral load as predictor",
    "text": "A) Log10 Viral load as predictor\n\n1. Positive test count 7DMA ~ VL 7DMA\n\nViz\n\n#check distribution of outcome (more normal when natural log transformed)\nhist(log(data$case_pcr_pos_7dma))\n\n\n\n#non log transformed positive tests\nhist(data$case_pcr_pos_7dma)\n\n\n\n#distribution of predictor (somewhat normally distributed)\nhist(log10(data$vl_7dma)) \n\n\n\n# Viral Load vs Positive Test Count\nplot(log10(case_pcr_pos_7dma)~ log10(vl_7dma), data=data)\n\n\n\n\n\n\nModel (Viral Load 7DMA predicts Positive Test 7DMA)\n\nrecipe1 &lt;- recipe(case_pcr_pos_7dma ~ log10_vl_7dma, data = train) #recipe \n####################################################################################\nworkflow1 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe1) #model workflow\n####################################################################################\nset.seed(13)\nfit1 &lt;- workflow1 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit1) \n\n\n\n  \n\n\n####################################################################################\naug_train1 &lt;- augment(fit1, train)\naug_train1 %&gt;% select(case_pcr_pos_7dma, .pred) #make predictions on train data\n\n\n\n  \n\n\n####################################################################################\nset.seed(13)\nfolds1 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_pcr_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv1 &lt;- fit_resamples(workflow1, resamples = folds1)\ncv1_metrics &lt;- collect_metrics(cv1)\ncv1_metrics #check cross validation metrics\n\n\n\n  \n\n\n####################################################################################\nworkflow_null1 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe1)\n\nnull_cv_metrics1 &lt;- fit_resamples(workflow_null1, resamples = folds1)\n\ncollect_metrics(null_cv_metrics1) #check null model\n\n\n\n  \n\n\n####################################################################################\nrmse1 &lt;- aug_train1 %&gt;% rmse(truth = case_pcr_pos_7dma, .pred)\nrsq1 &lt;- aug_train1 %&gt;% rsq(truth = case_pcr_pos_7dma, .pred)\nm1_metrics &lt;- full_join(rmse1, rsq1)\nm1_metrics #check metrics of predictions on train data\n\n\n\n  \n\n\n####################################################################################\naug_train1 %&gt;% ggplot(aes(case_pcr_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 5 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 5 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n2. Natural log positive test count 7DMA ~ log10 VL 7DMA\n\nViz\n\n#check distribution of outcome variable (more normal when natural log transformed)\nhist(data$log_case_pos_7dma) \n\n\n\n#distribution of predictor variable (somewhat normally distributed)\nhist(log10(data$vl_7dma)) \n\n\n\n# Viral Load vs Log Positive Test Count\nplot(log_case_pos_7dma~ log10(vl_7dma), data=data)\n\n\n\n\n\n\nModel (Viral Load 7DMA predicts Log Positive Test 7DMA)\n\nrecipe2 &lt;- recipe(log_case_pos_7dma ~ log10_vl_7dma, data = train) #recipe \n####################################################################################\nworkflow2 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe2) #model workflow\n####################################################################################\nset.seed(13)\nfit2 &lt;- workflow2 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit2) \n\n\n\n  \n\n\n####################################################################################\naug_train2 &lt;- augment(fit2, train)\naug_train2 %&gt;% select(log_case_pos_7dma, .pred) #make predictions on train data\n\n\n\n  \n\n\n####################################################################################\nset.seed(13)\nfolds2 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = log_case_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv2 &lt;- fit_resamples(workflow2, resamples = folds2)\ncv2_metrics &lt;- collect_metrics(cv2)\ncv2_metrics #check cross validation metrics\n\n\n\n  \n\n\n####################################################################################\nworkflow_null2 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe2)\n\nnull_cv_metrics2 &lt;- fit_resamples(workflow_null2, resamples = folds2)\n\ncollect_metrics(null_cv_metrics2) #check null model\n\n\n\n  \n\n\n####################################################################################\nrmse2 &lt;- aug_train2 %&gt;% rmse(truth = log_case_pos_7dma, .pred)\nrsq2 &lt;- aug_train2 %&gt;% rsq(truth = log_case_pos_7dma, .pred)\nm2_metrics &lt;- full_join(rmse2, rsq2)\nm2_metrics #check metrics of predictions on train data\n\n\n\n  \n\n\n####################################################################################\naug_train2 %&gt;% ggplot(aes(log_case_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 5 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 5 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n3. Test positivity rate 7DMA ~ log10 VL 7DMA\n\nhist(data$case_prop_pos_7dma) #check distribution of outcome variable (somewhat skewed)\n\n\n\nhist(log10(data$vl_7dma)) #distribution of predictor variable (somewhat normally except for observations near LOD\n\n\n\n# Viral Load vs Test PR\nplot(case_prop_pos_7dma ~ log10(vl_7dma), data=data)\n\n\n\n\n\nModel (Viral Load 7DMA predicts Test Pos Rate 7DMA)\n\nrecipe3 &lt;- recipe(case_prop_pos_7dma ~ log10_vl_7dma, data = train) #recipe \n####################################################################################\nworkflow3 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe3) #model workflow\n####################################################################################\nset.seed(13)\nfit3 &lt;- workflow3 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit3) \n\n\n\n  \n\n\n####################################################################################\naug_train3 &lt;- augment(fit3, train)\naug_train3 %&gt;% select(case_prop_pos_7dma, .pred) #make predictions on train data\n\n\n\n  \n\n\n####################################################################################\nset.seed(13)\nfolds3 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv3 &lt;- fit_resamples(workflow3, resamples = folds3)\ncv3_metrics &lt;- collect_metrics(cv3)\ncv3_metrics #check cross validation metrics\n\n\n\n  \n\n\n####################################################################################\nworkflow_null3 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe3)\n\nnull_cv_metrics3 &lt;- fit_resamples(workflow_null3, resamples = folds3)\n\ncollect_metrics(null_cv_metrics3) #check null model\n\n\n\n  \n\n\n####################################################################################\nrmse3 &lt;- aug_train3 %&gt;% rmse(truth = case_prop_pos_7dma, .pred)\nrsq3 &lt;- aug_train3 %&gt;% rsq(truth = case_prop_pos_7dma, .pred)\nm3_metrics &lt;- full_join(rmse3, rsq3)\nm3_metrics #check metrics of predictions on train data\n\n\n\n  \n\n\n####################################################################################\naug_train3 %&gt;% ggplot(aes(case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 5 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 5 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n4. Natural log test positivity rate 7DMA ~ log10 VL 7DMA\n\nhist(data$log_case_prop_pos_7dma*100) #check distribution of outcome variable (more normally distributed)\n\n\n\nhist(log10(data$vl_7dma)) #distribution of predictor variable (somewhat normally distributed except values near LOD)\n\n\n\n# Viral Load vs Log Test PR\nplot(log_case_prop_pos_7dma*100 ~ log10(vl_7dma), data=data)\n\n\n\n\n\nModel (Viral Load 7DMA predicts Log Test Pos Rate 7DMA)\n\nrecipe4 &lt;- recipe(log_case_prop_pos_7dma ~ log10_vl_7dma, data = train) #recipe \n####################################################################################\nworkflow4 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe4) #model workflow\n####################################################################################\nset.seed(13)\nfit4 &lt;- workflow4 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit4) \n\n\n\n  \n\n\n####################################################################################\naug_train4 &lt;- augment(fit4, train)\naug_train4 %&gt;% select(log_case_prop_pos_7dma, .pred) #make predictions on train data\n\n\n\n  \n\n\n####################################################################################\nset.seed(13)\nfolds4 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = log_case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv4 &lt;- fit_resamples(workflow4, resamples = folds4)\ncv4_metrics &lt;- collect_metrics(cv4)\ncv4_metrics #check cross validation metrics\n\n\n\n  \n\n\n####################################################################################\nworkflow_null4 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe4)\n\nnull_cv_metrics4 &lt;- fit_resamples(workflow_null4, resamples = folds4)\n\ncollect_metrics(null_cv_metrics4) #check null model\n\n\n\n  \n\n\n####################################################################################\nrmse4 &lt;- aug_train4 %&gt;% rmse(truth = log_case_prop_pos_7dma, .pred)\nrsq4 &lt;- aug_train4 %&gt;% rsq(truth = log_case_prop_pos_7dma, .pred)\nm4_metrics &lt;- full_join(rmse4, rsq4)\nm4_metrics #check metrics of predictions on train data\n\n\n\n  \n\n\n####################################################################################\naug_train4 %&gt;% ggplot(aes(log_case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 5 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 5 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#b-qpcr-positivity-rate-as-predictor",
    "href": "code/analysis/4_univariate_regressions.html#b-qpcr-positivity-rate-as-predictor",
    "title": "Univariate Linear Regressions",
    "section": "B) qPCR positivity rate as predictor",
    "text": "B) qPCR positivity rate as predictor\n\n1. Positive test 7DMA ~ WW PR 7DMA\n\nViz\n\nhist(log10(data$case_pcr_pos_7dma)) #check distribution of outcome variable, more normal when log transformed\n\n\n\nhist(data$pr_7dma) #distribution of predictor variable \n\n\n\nplot(log10(case_pcr_pos_7dma) ~ pr_7dma, data=data) #log-transformed looks better\n\n\n\n#WW PR vs Test Pos\nplot(case_pcr_pos_7dma ~ pr_7dma, data=data) \n\n\n\n\n\n\nModel (WW PR 7DMA predicts Test Positive 7DMA)\n\nrecipe5 &lt;- recipe(case_pcr_pos_7dma ~ pr_7dma, data = train) #recipe \n####################################################################################\nworkflow5 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe5) #model workflow\n####################################################################################\nset.seed(13)\nfit5 &lt;- workflow5 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit5) \n\n\n\n  \n\n\n####################################################################################\naug_train5 &lt;- augment(fit5, train)\naug_train5 %&gt;% select(case_pcr_pos_7dma, .pred) #make predictions on train data\n\n\n\n  \n\n\n####################################################################################\nset.seed(13)\nfolds5 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_pcr_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv5 &lt;- fit_resamples(workflow5, resamples = folds5)\ncv5_metrics &lt;- collect_metrics(cv5)\ncv5_metrics #check cross validation metrics\n\n\n\n  \n\n\n####################################################################################\nworkflow_null5 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe5)\n\nnull_cv_metrics5 &lt;- fit_resamples(workflow_null5, resamples = folds5)\n\ncollect_metrics(null_cv_metrics5) #check null model\n\n\n\n  \n\n\n####################################################################################\nrmse5 &lt;- aug_train5 %&gt;% rmse(truth = case_pcr_pos_7dma, .pred)\nrsq5 &lt;- aug_train5 %&gt;% rsq(truth = case_pcr_pos_7dma, .pred)\nm5_metrics &lt;- full_join(rmse5, rsq5)\nm5_metrics #check metrics of predictions on train data\n\n\n\n  \n\n\n####################################################################################\naug_train5 %&gt;% ggplot(aes(case_pcr_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 8 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 8 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n2. Natural log positive test count\n\nModel\n\nrecipe6 &lt;- recipe(log_case_pos_7dma ~ pr_7dma, data = train) #recipe \n####################################################################################\nworkflow6 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe6) #model workflow\n####################################################################################\nset.seed(13)\nfit6 &lt;- workflow6 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit6) \n\n\n\n  \n\n\n####################################################################################\naug_train6 &lt;- augment(fit6, train)\naug_train6 %&gt;% select(log_case_pos_7dma, .pred) #make predictions on train data\n\n\n\n  \n\n\n####################################################################################\nset.seed(13)\nfolds6 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = log_case_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv6 &lt;- fit_resamples(workflow6, resamples = folds6)\ncv6_metrics &lt;- collect_metrics(cv6)\ncv6_metrics #check cross validation metrics\n\n\n\n  \n\n\n####################################################################################\nworkflow_null6 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe6)\n\nnull_cv_metrics6 &lt;- fit_resamples(workflow_null6, resamples = folds6)\n\ncollect_metrics(null_cv_metrics6) #check null model\n\n\n\n  \n\n\n####################################################################################\nrmse6 &lt;- aug_train6 %&gt;% rmse(truth = log_case_pos_7dma, .pred)\nrsq6 &lt;- aug_train6 %&gt;% rsq(truth = log_case_pos_7dma, .pred)\nm6_metrics &lt;- full_join(rmse6, rsq6)\nm6_metrics #check metrics of predictions on train data\n\n\n\n  \n\n\n####################################################################################\naug_train6 %&gt;% ggplot(aes(log_case_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 8 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 8 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n3. Test positivity rate 7DMA ~ WW PR 7DMA\n\nViz\n\nhist(data$case_prop_pos_7dma) #check distribution of dependent variable \n\n\n\nhist(data$pr_7dma) #distribution of independent variable \n\n\n\nplot(case_prop_pos_7dma ~ pr_7dma, data=data)\n\n\n\n\n\n\nModel\n\nrecipe7 &lt;- recipe(case_prop_pos_7dma ~ pr_7dma, data = train) #recipe \n####################################################################################\nworkflow7 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe7) #model workflow\n####################################################################################\nset.seed(13)\nfit7 &lt;- workflow7 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit7) \n\n\n\n  \n\n\n####################################################################################\naug_train7 &lt;- augment(fit7, train)\naug_train7 %&gt;% select(case_prop_pos_7dma, .pred) #make predictions on train data\n\n\n\n  \n\n\n####################################################################################\nset.seed(13)\nfolds7 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv7 &lt;- fit_resamples(workflow7, resamples = folds7)\ncv7_metrics &lt;- collect_metrics(cv7)\ncv7_metrics #check cross validation metrics\n\n\n\n  \n\n\n####################################################################################\nworkflow_null7 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe7)\n\nnull_cv_metrics7 &lt;- fit_resamples(workflow_null7, resamples = folds7)\n\ncollect_metrics(null_cv_metrics7) #check null model\n\n\n\n  \n\n\n####################################################################################\nrmse7 &lt;- aug_train7 %&gt;% rmse(truth = case_prop_pos_7dma, .pred)\nrsq7 &lt;- aug_train7 %&gt;% rsq(truth = case_prop_pos_7dma, .pred)\nm7_metrics &lt;- full_join(rmse7, rsq7)\nm7_metrics #check metrics of predictions on train data\n\n\n\n  \n\n\n####################################################################################\naug_train7 %&gt;% ggplot(aes(case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 8 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 8 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#log-qpcr-positivity-rate-as-predictor",
    "href": "code/analysis/4_univariate_regressions.html#log-qpcr-positivity-rate-as-predictor",
    "title": "Univariate Linear Regressions",
    "section": "4. Log qPCR positivity rate as predictor",
    "text": "4. Log qPCR positivity rate as predictor\n\nTest positivity rate 7DMA ~ Log WW PR\n\nViz\n\nhist(data$case_prop_pos_7dma) #check distribution of dependent variable \n\n\n\nhist(data$log_pr_7dma) #distribution of independent variable \n\n\n\nplot(case_prop_pos_7dma ~ log_pr_7dma, data=data)\n\n\n\n\n\n\nModel\n\nrecipe8 &lt;- recipe(case_prop_pos_7dma ~ log_pr_7dma, data = train) #recipe \n####################################################################################\nworkflow8 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe8) #model workflow\n####################################################################################\nset.seed(13)\nfit8 &lt;- workflow8 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit8) \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    -6.56     2.21      -2.96 4.26e- 3\n2 log_pr_7dma     5.11     0.669      7.64 1.37e-10\n\n####################################################################################\naug_train8 &lt;- augment(fit8, train)\naug_train8 %&gt;% select(case_prop_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   case_prop_pos_7dma  .pred\n                &lt;dbl&gt;  &lt;dbl&gt;\n 1              9.02   8.96 \n 2             15.5   16.2  \n 3              5.70  12.4  \n 4             15.0   16.4  \n 5              3.83   4.55 \n 6              4.03  10.3  \n 7              4.36  11.7  \n 8              0.592 -0.868\n 9              1.84   7.96 \n10              9.99  10.5  \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds8 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv8 &lt;- fit_resamples(workflow8, resamples = folds8)\ncv8_metrics &lt;- collect_metrics(cv8)\ncv8_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   5.10     25  0.286  Preprocessor1_Model1\n2 rsq     standard   0.561    25  0.0214 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null8 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe8)\n\nnull_cv_metrics8 &lt;- fit_resamples(workflow_null8, resamples = folds8)\n\ncollect_metrics(null_cv_metrics8) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     6.70    25   0.321 Preprocessor1_Model1\n2 rsq     standard   NaN        0  NA     Preprocessor1_Model1\n\n####################################################################################\nrmse8 &lt;- aug_train8 %&gt;% rmse(truth = case_prop_pos_7dma, .pred)\nrsq8 &lt;- aug_train8 %&gt;% rsq(truth = case_prop_pos_7dma, .pred)\nm8_metrics &lt;- full_join(rmse8, rsq8)\nm8_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       5.12 \n2 rsq     standard       0.477\n\n####################################################################################\naug_train8 %&gt;% ggplot(aes(case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 7 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 7 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#notes",
    "href": "code/analysis/4_univariate_regressions.html#notes",
    "title": "Univariate Linear Regressions",
    "section": "Notes",
    "text": "Notes\n\nModel B3 seems to be performing the best so far (out of A1-4, B1-4) but no model is significantly out-performing the others yet\nMany distributions are not normal and transformations do not help with normality, is this still okay to do linear regressions with?\nWhat if something is potentially bimodally distributed? (see histogram for pr_7dma)"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#next-steps-as-of-111723",
    "href": "code/analysis/4_univariate_regressions.html#next-steps-as-of-111723",
    "title": "Univariate Linear Regressions",
    "section": "Next Steps (as of 11/17/23)",
    "text": "Next Steps (as of 11/17/23)\n\nneed to do model validation steps with the reserved 20% testing data\nneed to see how models will perform on the testing dates (April 2022-end of series)\nneed to build more univariate models, then move on to multivariates"
  },
  {
    "objectID": "aboutme.html#leah-lariscy-second-year-phd-student",
    "href": "aboutme.html#leah-lariscy-second-year-phd-student",
    "title": "About Me!",
    "section": "",
    "text": "University of Georgia Environmental Health Science\n\n\n\nErin Lipp\nTravis Glenn"
  },
  {
    "objectID": "aboutme.html#leah-lariscy-2nd-year-phd-student",
    "href": "aboutme.html#leah-lariscy-2nd-year-phd-student",
    "title": "About me!",
    "section": "",
    "text": "University of Georgia Environmental Health Science\n\n\n\nErin Lipp\nTravis Glenn\n\n\n\nAndreas Handel"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#c-log-qpcr-positivity-rate-as-predictor",
    "href": "code/analysis/4_univariate_regressions.html#c-log-qpcr-positivity-rate-as-predictor",
    "title": "Univariate Linear Regressions",
    "section": "C) Log qPCR positivity rate as predictor",
    "text": "C) Log qPCR positivity rate as predictor\n\n1. Test positivity rate 7DMA ~ Log WW PR\n\nViz\n\nhist(data$case_prop_pos_7dma) #check distribution of dependent variable \n\n\n\nhist(data$log_pr_7dma) #distribution of independent variable \n\n\n\nplot(case_prop_pos_7dma ~ log_pr_7dma, data=data)\n\n\n\n\n\n\nModel\n\nrecipe8 &lt;- recipe(case_prop_pos_7dma ~ log_pr_7dma, data = train) #recipe \n####################################################################################\nworkflow8 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe8) #model workflow\n####################################################################################\nset.seed(13)\nfit8 &lt;- workflow8 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit8) \n\n\n\n  \n\n\n####################################################################################\naug_train8 &lt;- augment(fit8, train)\naug_train8 %&gt;% select(case_prop_pos_7dma, .pred) #make predictions on train data\n\n\n\n  \n\n\n####################################################################################\nset.seed(13)\nfolds8 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv8 &lt;- fit_resamples(workflow8, resamples = folds8)\ncv8_metrics &lt;- collect_metrics(cv8)\ncv8_metrics #check cross validation metrics\n\n\n\n  \n\n\n####################################################################################\nworkflow_null8 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe8)\n\nnull_cv_metrics8 &lt;- fit_resamples(workflow_null8, resamples = folds8)\n\ncollect_metrics(null_cv_metrics8) #check null model\n\n\n\n  \n\n\n####################################################################################\nrmse8 &lt;- aug_train8 %&gt;% rmse(truth = case_prop_pos_7dma, .pred)\nrsq8 &lt;- aug_train8 %&gt;% rsq(truth = case_prop_pos_7dma, .pred)\nm8_metrics &lt;- full_join(rmse8, rsq8)\nm8_metrics #check metrics of predictions on train data\n\n\n\n  \n\n\n####################################################################################\naug_train8 %&gt;% ggplot(aes(case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 8 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 8 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "ReadMe.html",
    "href": "ReadMe.html",
    "title": "Read Me",
    "section": "",
    "text": "Abbreviation\nDescription\n\n\n\n\nN1\nN1 target on SARSCOV2 genome, used for qPCR\n\n\nN2\nN2 target on SARSCOV2 genome, used for qPCR\n\n\nWBE\nWastewater-based epidemiology\n\n\nWW\nWastewater\n\n\nVL\nWastewater viral load (total copies per day)\n\n\n7-DMA\nSeven-day moving average\n\n\nWWTP\nWastewater treatment plant\n\n\nPR\nPositivity rate (detection frequency)\n\n\nCOVID\nGenerally refers to clinical data sets from GA DPH\n\n\n\n\n\n\nTo understand how these data were generated, please see scripts 1 and 2.\nGenerally speaking, this data set has been summarized by week, so there is one observation per week for the entire series.\nVariables of interest are italicized.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nweek\nYear, week of observation\n\n\nn1_vl\nViral load estimated by N1 qPCR assay\n\n\nn2_vl\nViral load estimated by N2 qPCR assay\n\n\navg_vl\nViral load averaged across N1 and N2 assays\n\n\nvl_n1_7dma\nN1 viral load 7-day moving average\n\n\nvl_n2_7dma\nN2 viral load 7-day moving average\n\n\nvl_7dma\nViral load 7-day moving average, N1/N2 averaged\n\n\nn_reps_N1\nNumber of total N1 qPCR reactions\n\n\nn_reps_N2\nNumber of total N2 qPCR reactions\n\n\nn_reps\nNumber of total qPCR reactions\n\n\npos_rate_N1\nPositivity rate of N1 qPCR reactions\n\n\npos_rate_N2\nPositivity rate of N2 qPCR reactions\n\n\navg_pos_rate\nAverage positivity rate of all qPCR reactions\n\n\npr_n1_7dma\nPositivity rate 7-day moving average, N1\n\n\npr_n2_7dma\nPositivity rate 7-day moving average, N2\n\n\npr_7dma\nPositivity rate 7-day moving average, N1/N2 averaged\n\n\ncases.symptom.onset\nDPH data, number of cases with symptoms that began\n\n\nsymptom_onset_7dma\nCase symptom onset 7-day moving average\n\n\ncases.reported\nDPH data, number of cases reported\n\n\ncase_report_7dma\nCases reported 7-day moving average\n\n\npcr_tests\nDPH data, number of PCR tests administered\n\n\npcr_pos\nDPH data, number of positive PCR tests\n\n\npcr_pos_7dma\nPositive test 7-day moving average\n\n\ncase_pcr_pos_7dma\nDPH data (not calculated by me) positive test 7-day moving average\n\n\npcr_pos_14dma\nDPH data (not calculated by me) positive test 14-day moving average\n\n\nprop_pos\nPositivity rate of clinical tests\n\n\ncase_prop_pos_7dma\nPositivity rate of clinical tests 7-day moving average"
  },
  {
    "objectID": "ReadMe.html#data-legends",
    "href": "ReadMe.html#data-legends",
    "title": "Read Me",
    "section": "",
    "text": "Abbreviation\nDescription\n\n\n\n\nN1\nN1 target on SARSCOV2 genome, used for qPCR\n\n\nN2\nN2 target on SARSCOV2 genome, used for qPCR\n\n\nWBE\nWastewater-based epidemiology\n\n\nWW\nWastewater\n\n\nVL\nWastewater viral load (total copies per day)\n\n\n7-DMA\nSeven-day moving average\n\n\nWWTP\nWastewater treatment plant\n\n\nPR\nPositivity rate (detection frequency)\n\n\nCOVID\nGenerally refers to clinical data sets from GA DPH\n\n\n\n\n\n\nTo understand how these data were generated, please see scripts 1 and 2.\nGenerally speaking, this data set has been summarized by week, so there is one observation per week for the entire series.\nVariables of interest are italicized.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nweek\nYear, week of observation\n\n\nn1_vl\nViral load estimated by N1 qPCR assay\n\n\nn2_vl\nViral load estimated by N2 qPCR assay\n\n\navg_vl\nViral load averaged across N1 and N2 assays\n\n\nvl_n1_7dma\nN1 viral load 7-day moving average\n\n\nvl_n2_7dma\nN2 viral load 7-day moving average\n\n\nvl_7dma\nViral load 7-day moving average, N1/N2 averaged\n\n\nn_reps_N1\nNumber of total N1 qPCR reactions\n\n\nn_reps_N2\nNumber of total N2 qPCR reactions\n\n\nn_reps\nNumber of total qPCR reactions\n\n\npos_rate_N1\nPositivity rate of N1 qPCR reactions\n\n\npos_rate_N2\nPositivity rate of N2 qPCR reactions\n\n\navg_pos_rate\nAverage positivity rate of all qPCR reactions\n\n\npr_n1_7dma\nPositivity rate 7-day moving average, N1\n\n\npr_n2_7dma\nPositivity rate 7-day moving average, N2\n\n\npr_7dma\nPositivity rate 7-day moving average, N1/N2 averaged\n\n\ncases.symptom.onset\nDPH data, number of cases with symptoms that began\n\n\nsymptom_onset_7dma\nCase symptom onset 7-day moving average\n\n\ncases.reported\nDPH data, number of cases reported\n\n\ncase_report_7dma\nCases reported 7-day moving average\n\n\npcr_tests\nDPH data, number of PCR tests administered\n\n\npcr_pos\nDPH data, number of positive PCR tests\n\n\npcr_pos_7dma\nPositive test 7-day moving average\n\n\ncase_pcr_pos_7dma\nDPH data (not calculated by me) positive test 7-day moving average\n\n\npcr_pos_14dma\nDPH data (not calculated by me) positive test 14-day moving average\n\n\nprop_pos\nPositivity rate of clinical tests\n\n\ncase_prop_pos_7dma\nPositivity rate of clinical tests 7-day moving average"
  }
]