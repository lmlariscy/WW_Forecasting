[
  {
    "objectID": "code/processing/1_initial_cleaning.html",
    "href": "code/processing/1_initial_cleaning.html",
    "title": "Raw data processing",
    "section": "",
    "text": "This script does the following:\n\nLoads raw data files\nChecks for missing data in all raw data files\nConverts qPCR non-detects to NAs\nCalculates LOD and LOQ values for all four assays\nTransforms NAs to LOD for each assay\nBinds all qPCR data sets with WWTP data\nBinds all DPH COVID data"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#info",
    "href": "code/processing/1_initial_cleaning.html#info",
    "title": "Raw data processing",
    "section": "",
    "text": "This script does the following:\n\nLoads raw data files\nChecks for missing data in all raw data files\nConverts qPCR non-detects to NAs\nCalculates LOD and LOQ values for all four assays\nTransforms NAs to LOD for each assay\nBinds all qPCR data sets with WWTP data\nBinds all DPH COVID data"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#load-packages",
    "href": "code/processing/1_initial_cleaning.html#load-packages",
    "title": "Raw data processing",
    "section": "Load packages",
    "text": "Load packages\n\nknitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(here)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stats)"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#load-raw-data",
    "href": "code/processing/1_initial_cleaning.html#load-raw-data",
    "title": "Raw data processing",
    "section": "Load raw data",
    "text": "Load raw data\n\n# Load N1 data\nn1_stepone_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/stepone_n1_FINAL_UPDATE.csv\")) #year 1 data\nn1_cfx_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/cfx_n1_FINAL_UPDATE.csv\")) #year 2 data\n\n# Load N2 data\nn2_stepone_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/stepone_n2_FINAL_UPDATE.csv\")) #year 1 data\nn2_cfx_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/cfx_n2_FINAL_UPDATE.csv\")) #year 2 data\n\n# Load Plant data\nplant_v2 &lt;- read_csv(here(\"data/raw_data/updated_data/plant_data_UPDATED.csv\"))\n\n# Load COVID-19 Symptom data\ncovid_symptom &lt;- read_csv(here(\"data/raw_data/ga_covid_data/epicurve_symptom_date.csv\")) %&gt;% \n  filter(county==\"Clarke\") %&gt;% \n  select(symptom.date=`symptom date`, \n         cases, moving_avg_cases)\n\n#Load COVID-19 Confirmed Case Data\ncovid_case &lt;- read_csv(here(\"data/raw_data/ga_covid_data/epicurve_rpt_date.csv\")) %&gt;% \n  filter(county==\"Clarke\") %&gt;% \n  select(report_date, \n         cases, \n         moving_avg_cases)\n\n#Load COVID-19 Testing Data\ncovid_testing &lt;- read_csv(here(\"data/raw_data/ga_covid_data/pcr_antigen_col.csv\")) %&gt;% \n  filter(county==\"Clarke\") %&gt;% \n  select(collection_date = collection_dt, \n         pcr_tests = `ALL PCR tests performed`, \n         pcr_pos = `All PCR positive tests`, \n         pcr_pos_7dma = `7 day percent positive`,\n         pcr_pos_14dma = `14 day percent positive`)\n\n#Load CFX recovery data\nrecovery_output &lt;- read_csv(here(\"data/raw_data/recovery_data.csv\"))\nrecovery_input &lt;- read_csv(here(\"data/raw_data/calfguard.csv\"))\n\n#Load Hospitalization data\n#hospitalization &lt;- read_csv(here(\"data/raw_data/hospitalizations.csv\"))"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#create-df-to-check-for-missing-collections",
    "href": "code/processing/1_initial_cleaning.html#create-df-to-check-for-missing-collections",
    "title": "Raw data processing",
    "section": "Create df to check for missing collections",
    "text": "Create df to check for missing collections\n\n#Year 1\nnumbers &lt;- 7:92\nnumbers_tbl &lt;- tibble(\"collection_num\"=numbers)\n\n#Year 2\nnumbers2 &lt;- 93:243\nnumbers2_tbl &lt;- tibble(\"collection_num\" =numbers2)\n\n#full time series (for plant data)\nnumbers3 &lt;- 7:243\nnumbers3_tbl &lt;- tibble(\"Collection\" =numbers3)"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#glance-at-data",
    "href": "code/processing/1_initial_cleaning.html#glance-at-data",
    "title": "Raw data processing",
    "section": "Glance at data",
    "text": "Glance at data\n\nStepOne N1\n\nCount observations for each collection number\n\n#count observations for each collection date, then visualize\nn1_stepone_v2 %&gt;% count(collection_num) %&gt;% ggplot(aes(n)) +\n  geom_histogram()\n\n\n\nn1_stepone_v2 %&gt;% ggplot(aes(collection_num)) + \n  geom_histogram(binwidth = 1) #max should be either 27 or 54\n\n\n\n\n\n\nCount observations for each biological replicate\n\n#count observations for each sample id/biological rep, then visualize\nn1_stepone_v2 %&gt;% count(sample_id) %&gt;% ggplot(aes(n)) + \n  geom_histogram() #there should be 3 technical reps\n\n\n\n#check which collections have more than 3 technical reps\nn1_stepone_v2 %&gt;% count(sample_id) %&gt;% filter(n&gt;3)\n\n# A tibble: 10 × 2\n   sample_id     n\n   &lt;chr&gt;     &lt;int&gt;\n 1 MI_19_A       6\n 2 MI_19_B       6\n 3 MI_7_C        6\n 4 NO_19_A       6\n 5 NO_19_B       6\n 6 NO_65_B       6\n 7 NO_7_A        6\n 8 NO_7_C        9\n 9 NO_8_A        6\n10 NO_9_A        6\n\n\n\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_n1_stepone &lt;- n1_stepone_v2 %&gt;% count(collection_num) \ncount_n1_stepone &lt;- merge(count_n1_stepone, numbers_tbl, by=\"collection_num\", all.y=T)\n\ncount_n1_stepone\n\n   collection_num  n\n1               7 33\n2               8 21\n3               9 15\n4              10 18\n5              11 18\n6              12 18\n7              13 18\n8              14 18\n9              15 18\n10             16 18\n11             17 18\n12             18 30\n13             19 30\n14             20 18\n15             21 18\n16             22 27\n17             23 27\n18             24 27\n19             25 27\n20             26 27\n21             27 27\n22             28 27\n23             29 27\n24             30 27\n25             31 27\n26             32 24\n27             33 27\n28             34 27\n29             35 27\n30             36 27\n31             37 27\n32             38 27\n33             39 27\n34             40 NA\n35             41 27\n36             42 27\n37             43 27\n38             44 27\n39             45 27\n40             46 27\n41             47 27\n42             48 27\n43             49 27\n44             50 27\n45             51 27\n46             52 27\n47             53 27\n48             54 27\n49             55 27\n50             56 27\n51             57 27\n52             58 27\n53             59 27\n54             60 27\n55             61 27\n56             62 27\n57             63 27\n58             64 27\n59             65 57\n60             66 54\n61             67 54\n62             68 54\n63             69 54\n64             70 54\n65             71 54\n66             72 54\n67             73 54\n68             74 36\n69             75 54\n70             76 27\n71             77 54\n72             78 54\n73             79 27\n74             80 27\n75             81 54\n76             82 36\n77             83 54\n78             84 27\n79             85 54\n80             86 54\n81             87 54\n82             88 54\n83             89 54\n84             90 54\n85             91 54\n86             92 54\n\n#collection 40 is missing, but this is expected\n\n\n\n\nStepOne N2\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_n2_stepone &lt;- n2_stepone_v2 %&gt;% count(collection_num) \ncount_n2_stepone &lt;- merge(count_n2_stepone, numbers_tbl, by=\"collection_num\", all.y=T)\n\ncount_n2_stepone\n\n   collection_num  n\n1               7 33\n2               8 21\n3               9 15\n4              10 18\n5              11 18\n6              12 18\n7              13 18\n8              14 18\n9              15 18\n10             16 18\n11             17 18\n12             18 30\n13             19 30\n14             20 18\n15             21 18\n16             22 27\n17             23 27\n18             24 27\n19             25 27\n20             26 27\n21             27 27\n22             28 27\n23             29 27\n24             30 27\n25             31 27\n26             32 24\n27             33 27\n28             34 27\n29             35 27\n30             36 27\n31             37 27\n32             38 27\n33             39 27\n34             40 NA\n35             41 27\n36             42 27\n37             43 27\n38             44 27\n39             45 27\n40             46 27\n41             47 27\n42             48 27\n43             49 27\n44             50 27\n45             51 27\n46             52 27\n47             53 27\n48             54 27\n49             55 24\n50             56 27\n51             57 27\n52             58 27\n53             59 27\n54             60 27\n55             61 27\n56             62 27\n57             63 27\n58             64 27\n59             65 54\n60             66 54\n61             67 54\n62             68 54\n63             69 54\n64             70 54\n65             71 54\n66             72 54\n67             73 54\n68             74 35\n69             75 54\n70             76 27\n71             77 54\n72             78 53\n73             79 24\n74             80 27\n75             81 54\n76             82 36\n77             83 54\n78             84 27\n79             85 54\n80             86 54\n81             87 54\n82             88 54\n83             89 54\n84             90 54\n85             91 54\n86             92 54\n\n#collection 40 is missing, but this is expected\n\n\n\nCount observations for each collection number\n\n#count observations for each collection date, then visualize\nn2_stepone_v2 %&gt;% count(collection_num) %&gt;% ggplot(aes(n)) +\n  geom_histogram()\n\n\n\nn2_stepone_v2 %&gt;% ggplot(aes(collection_num)) + \n  geom_histogram(binwidth = 1) #max should be either 27 or 54\n\n\n\n\n\n\nCount observations for each biological replicate\n\n#count observations for each sample id/biological rep, then visualize\nn2_stepone_v2 %&gt;% count(sample_id) %&gt;% ggplot(aes(n)) + \n  geom_histogram() #there should be 3 technical reps\n\n\n\n#check which collections have more than 3 technical reps\nn2_stepone_v2 %&gt;% count(sample_id) %&gt;% filter(n&gt;3)\n\n# A tibble: 10 × 2\n   sample_id     n\n   &lt;chr&gt;     &lt;int&gt;\n 1 MI_19_A       6\n 2 MI_19_B       6\n 3 MI_7_C        6\n 4 NO_19_A       6\n 5 NO_19_B       6\n 6 NO_65_B       6\n 7 NO_7_A        6\n 8 NO_7_C        9\n 9 NO_8_A        6\n10 NO_9_A        6\n\n\n\n\n\nCFX N1\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_n1_cfx &lt;- n1_cfx_v2 %&gt;% count(collection_num) \ncount_n1_cfx &lt;- merge(count_n1_cfx, numbers2_tbl, by=\"collection_num\", all.y=T)\ncount_n1_cfx\n\n    collection_num  n\n1               93 27\n2               94 NA\n3               95 54\n4               96 54\n5               97 54\n6               98 54\n7               99 54\n8              100 54\n9              101 54\n10             102 54\n11             103 54\n12             104 54\n13             105 48\n14             106 48\n15             107 27\n16             108 27\n17             109 54\n18             110 54\n19             111 54\n20             112 54\n21             113 54\n22             114 54\n23             115 54\n24             116 54\n25             117 54\n26             118 54\n27             119 54\n28             120 54\n29             121 54\n30             122 54\n31             123 54\n32             124 54\n33             125 54\n34             126 54\n35             127 54\n36             128 54\n37             129 54\n38             130 54\n39             131 54\n40             132 54\n41             133 54\n42             134 54\n43             135 NA\n44             136 54\n45             137 54\n46             138 54\n47             139 53\n48             140 54\n49             141 54\n50             142 54\n51             143 54\n52             144 54\n53             145 54\n54             146 54\n55             147 54\n56             148 54\n57             149 54\n58             150 54\n59             151 54\n60             152 54\n61             153 54\n62             154 54\n63             155 54\n64             156 54\n65             157 54\n66             158 54\n67             159 54\n68             160 54\n69             161 54\n70             162 54\n71             163 54\n72             164 36\n73             165 36\n74             166 54\n75             167 54\n76             168 54\n77             169 54\n78             170 54\n79             171 54\n80             172 54\n81             173 54\n82             174 54\n83             175 54\n84             176 54\n85             177 NA\n86             178 54\n87             179 54\n88             180 54\n89             181 54\n90             182 54\n91             183 54\n92             184 54\n93             185 54\n94             186 54\n95             187 54\n96             188 54\n97             189 54\n98             190 54\n99             191 54\n100            192 54\n101            193 54\n102            194 54\n103            195 54\n104            196 54\n105            197 54\n106            198 54\n107            199 54\n108            200 54\n109            201 54\n110            202 54\n111            203 54\n112            204 54\n113            205 54\n114            206 54\n115            207 54\n116            208 54\n117            209 54\n118            210 27\n119            211 27\n120            212 54\n121            213 NA\n122            214 54\n123            215 54\n124            216 54\n125            217 54\n126            218 57\n127            219 54\n128            220 54\n129            221 54\n130            222 27\n131            223 27\n132            224 54\n133            225 54\n134            226 54\n135            227 54\n136            228 51\n137            229 54\n138            230 27\n139            231 27\n140            232 54\n141            233 54\n142            234 54\n143            235 54\n144            236 54\n145            237 54\n146            238 54\n147            239 54\n148            240 54\n149            241 54\n150            242 54\n151            243 54\n\n\n\n\nCount observations for each collection number\n\n#count observations for each collection date, then visualize\nn1_cfx_v2 %&gt;% count(collection_num) %&gt;% ggplot(aes(n)) +\n  geom_histogram()\n\n\n\nn1_cfx_v2 %&gt;% ggplot(aes(collection_num)) + \n  geom_histogram(binwidth = 1) #max should be 54\n\n\n\n\n\n\nCheck which collections are doubled\n\n#check which collections are doubled\ncount_n1_cfx %&gt;% filter(n==108)\n\n[1] collection_num n             \n&lt;0 rows&gt; (or 0-length row.names)\n\n\n\n\nCount observations for each biological replicate\n\n#count observations for each sample id/biological rep, then visualize\nn1_cfx_v2 %&gt;% count(sample_id) %&gt;% ggplot(aes(n)) + \n  geom_histogram() #there should be 3 technical reps\n\n\n\n#almost all have 3 replicates, but there is a small amount with 6\n\n#check which collections have more than 3 technical reps\nn1_cfx_v2 %&gt;% count(sample_id) %&gt;% filter(n&gt;3)\n\n# A tibble: 1 × 2\n  sample_id     n\n  &lt;chr&gt;     &lt;int&gt;\n1 MI_218_C      6\n\n\n\n\n\nCFX N2\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_n2_cfx &lt;- n2_cfx_v2 %&gt;% count(collection_num) \ncount_n2_cfx &lt;- merge(count_n2_cfx, numbers2_tbl, by=\"collection_num\", all.y=T)\ncount_n2_cfx\n\n    collection_num  n\n1               93 27\n2               94 NA\n3               95 54\n4               96 54\n5               97 54\n6               98 57\n7               99 54\n8              100 54\n9              101 54\n10             102 54\n11             103 54\n12             104 54\n13             105 48\n14             106 54\n15             107 18\n16             108 27\n17             109 54\n18             110 54\n19             111 54\n20             112 54\n21             113 54\n22             114 54\n23             115 54\n24             116 54\n25             117 54\n26             118 54\n27             119 54\n28             120 54\n29             121 54\n30             122 54\n31             123 54\n32             124 54\n33             125 54\n34             126 54\n35             127 54\n36             128 54\n37             129 54\n38             130 54\n39             131 54\n40             132 54\n41             133 54\n42             134 54\n43             135 NA\n44             136 54\n45             137 54\n46             138 54\n47             139 54\n48             140 54\n49             141 54\n50             142 54\n51             143 53\n52             144 18\n53             145 53\n54             146 53\n55             147 53\n56             148 53\n57             149 53\n58             150 53\n59             151 53\n60             152 53\n61             153 53\n62             154 53\n63             155 53\n64             156 53\n65             157 NA\n66             158 53\n67             159 53\n68             160 54\n69             161 54\n70             162 54\n71             163 54\n72             164 36\n73             165 36\n74             166 54\n75             167 48\n76             168 54\n77             169 54\n78             170 54\n79             171 54\n80             172 54\n81             173 54\n82             174 54\n83             175 54\n84             176 51\n85             177 NA\n86             178 54\n87             179 54\n88             180 54\n89             181 54\n90             182 54\n91             183 54\n92             184 54\n93             185 NA\n94             186 54\n95             187 54\n96             188 54\n97             189 54\n98             190 54\n99             191 54\n100            192 54\n101            193 54\n102            194 54\n103            195 54\n104            196 54\n105            197 54\n106            198 54\n107            199 54\n108            200 54\n109            201 54\n110            202 54\n111            203 54\n112            204 54\n113            205 54\n114            206 54\n115            207 54\n116            208 54\n117            209 54\n118            210 27\n119            211 24\n120            212 54\n121            213 NA\n122            214 54\n123            215 54\n124            216 54\n125            217 54\n126            218 54\n127            219 54\n128            220 54\n129            221 54\n130            222 27\n131            223 27\n132            224 54\n133            225 54\n134            226 54\n135            227 54\n136            228 51\n137            229 54\n138            230 27\n139            231 27\n140            232 54\n141            233 54\n142            234 54\n143            235 54\n144            236 54\n145            237 54\n146            238 54\n147            239 54\n148            240 54\n149            241 54\n150            242 45\n151            243 54\n\n\n\n\nCheck which collections are doubled\n\n#check which collections are doubled\ncount_n2_cfx %&gt;% filter(n==108)\n\n[1] collection_num n             \n&lt;0 rows&gt; (or 0-length row.names)\n\n\n\n\nCount observations for each biological replicate\n\n#count observations for each sample id/biological rep, then visualize\nn2_cfx_v2 %&gt;% count(sample_id) %&gt;% ggplot(aes(n)) + \n  geom_histogram() #there should be 3 technical reps\n\n\n\n#almost all have 3 replicates, but there is a small amount with 6 and some with 2\n\n#check which collections have more than 3 technical reps\nn2_cfx_v2 %&gt;% count(sample_id) %&gt;% filter(n&gt;3)\n\n# A tibble: 3 × 2\n  sample_id      n\n  &lt;chr&gt;      &lt;int&gt;\n1 CC_191_E       6\n2 MI_144_DEF     6\n3 MI_98_D        6\n\n\n\n\nCount observations for each collection number\n\n#count observations for each collection date, then visualize\nn2_cfx_v2 %&gt;% count(collection_num) %&gt;% ggplot(aes(n)) +\n  geom_histogram()\n\n\n\nn2_cfx_v2 %&gt;% ggplot(aes(collection_num)) + \n  geom_histogram(binwidth = 1) #max should be 54\n\n\n\n\n\n\n\nPlant data\n\nMerge data with number tibble to check missing collections\n\n#count observations for each collection number\n#merge with numbers tibble to check for missing collections\ncount_plant &lt;- plant_v2 %&gt;% count(Collection, date) \ncount_plant &lt;- merge(count_plant, numbers3_tbl, by=\"Collection\", all.y=T)\ncount_plant\n\n    Collection       date  n\n1            7 2020-06-30  3\n2            8 2020-07-07  3\n3            9 2020-07-14  3\n4           10 2020-07-21  3\n5           11 2020-07-28  3\n6           12 2020-08-04  3\n7           13 2020-08-11  3\n8           14 2020-08-18  3\n9           15 2020-08-25  3\n10          16 2020-09-01  3\n11          17 2020-09-08  3\n12          18 2020-09-15  3\n13          19 2020-09-22  3\n14          20 2020-09-29  3\n15          21 2020-10-06  3\n16          22 2020-10-13  3\n17          23 2020-10-20  3\n18          24 2020-10-27  3\n19          25 2020-11-02  3\n20          26 2020-11-04  3\n21          27 2020-11-09  3\n22          28 2020-11-11  3\n23          29 2020-11-16  3\n24          30 2020-11-18  3\n25          31 2020-11-23  3\n26          32 2020-11-25  3\n27          33 2020-11-30  3\n28          34 2020-12-02  3\n29          35 2020-12-07  3\n30          36 2020-12-09  3\n31          37 2020-12-14  3\n32          38 2020-12-16  3\n33          39 2020-12-21  3\n34          40 2020-12-23  3\n35          41 2020-12-28  3\n36          42 2021-01-04  3\n37          43 2021-01-11  3\n38          44 2021-01-13  3\n39          45 2021-01-19  3\n40          46 2021-01-20  3\n41          47 2021-01-25  3\n42          48 2021-01-27  3\n43          49 2021-02-01  3\n44          50 2021-02-03  3\n45          51 2021-02-08  3\n46          52 2021-02-10  3\n47          53 2021-02-15  3\n48          54 2021-02-17  3\n49          55 2021-02-22  3\n50          56 2021-02-24  3\n51          57 2021-03-01  3\n52          58 2021-03-03  3\n53          59 2021-03-08  3\n54          60 2021-03-10  3\n55          61 2021-03-15  3\n56          62 2021-03-17  3\n57          63 2021-03-22  3\n58          64 2021-03-24  3\n59          65 2021-03-29  3\n60          66 2021-03-31  3\n61          67 2021-04-05  3\n62          68 2021-04-07  3\n63          69 2021-04-12  3\n64          70 2021-04-14  3\n65          71 2021-04-19  3\n66          72 2021-04-21  3\n67          73 2021-04-26  3\n68          74 2021-04-28  3\n69          75 2021-05-03  3\n70          76 2021-05-05  3\n71          77 2021-05-10  3\n72          78 2021-05-12  3\n73          79 2021-05-17  3\n74          80 2021-05-19  3\n75          81 2021-05-24  3\n76          82 2021-05-26  3\n77          83 2021-06-01  3\n78          84 2021-06-02  3\n79          85 2021-06-07  3\n80          86 2021-06-09  3\n81          87 2021-06-14  3\n82          88 2021-06-16  3\n83          89 2021-06-21  3\n84          90 2021-06-23  3\n85          91 2021-06-28  3\n86          92 2021-06-30  3\n87          93 2021-07-06  3\n88          94 2021-07-07  3\n89          95 2021-07-12  3\n90          96 2021-07-14  3\n91          97 2021-07-19  3\n92          98 2021-07-21  3\n93          99 2021-07-26  3\n94         100 2021-07-28  3\n95         101 2021-08-02  3\n96         102 2021-08-04  3\n97         103 2021-08-09  3\n98         104 2021-08-11  3\n99         105 2021-08-16  3\n100        106 2021-08-18  3\n101        107 2021-08-23  3\n102        108 2021-08-25  3\n103        109 2021-08-30  3\n104        110 2021-09-01  3\n105        111 2021-09-07  3\n106        112 2021-09-08  3\n107        113 2021-09-13  3\n108        114 2021-09-15  3\n109        115 2021-09-20  3\n110        116 2021-09-22  3\n111        117 2021-09-27  3\n112        118 2021-09-29  3\n113        119 2021-10-04  3\n114        120 2021-10-06  3\n115        121 2021-10-11  3\n116        122 2021-10-13  3\n117        123 2021-10-18  3\n118        124 2021-10-20  3\n119        125 2021-10-25  3\n120        126 2021-10-27  3\n121        127 2021-11-01  3\n122        128 2021-11-03  3\n123        129 2021-11-08  3\n124        130 2021-11-10  3\n125        131 2021-11-15  3\n126        132 2021-11-17  3\n127        133 2021-11-22  3\n128        134 2021-11-29  3\n129        135 2021-12-01  3\n130        136 2021-12-06  3\n131        137 2021-12-08  3\n132        138 2021-12-13  3\n133        139 2021-12-15  3\n134        140 2021-12-20  3\n135        141 2021-12-27  3\n136        142 2022-01-03  3\n137        143 2022-01-05  3\n138        144 2022-01-10  3\n139        145 2022-01-12  3\n140        146 2022-01-17  3\n141        147 2022-01-19  3\n142        148 2022-01-24  3\n143        149 2022-01-26  3\n144        150 2022-01-31  3\n145        151 2022-02-02  3\n146        152 2022-02-07  3\n147        153 2022-02-09  3\n148        154 2022-02-14  3\n149        155 2022-02-16  3\n150        156 2022-02-21  3\n151        157 2022-02-23  3\n152        158 2022-02-28  3\n153        159 2022-03-02  3\n154        160 2022-03-07  3\n155        161 2022-03-09  3\n156        162 2022-03-14  3\n157        163 2022-03-16  3\n158        164 2022-03-21  3\n159        165 2022-03-23  3\n160        166 2022-03-28  3\n161        167 2022-03-30  3\n162        168 2022-04-04  3\n163        169 2022-04-06  3\n164        170 2022-04-11  3\n165        171 2022-04-13  3\n166        172 2022-04-18  3\n167        173 2022-04-20  3\n168        174 2022-04-25  3\n169        175 2022-04-27  3\n170        176 2022-05-02  3\n171        177       &lt;NA&gt; NA\n172        178 2022-05-09  3\n173        179 2022-05-11  3\n174        180 2022-05-16  3\n175        181 2022-05-18  3\n176        182 2022-05-23  3\n177        183 2022-05-25  3\n178        184 2022-05-31  3\n179        185 2022-06-01  3\n180        186 2022-06-06  3\n181        187 2022-06-08  3\n182        188 2022-06-13  3\n183        189 2022-06-15  3\n184        190 2022-06-20  3\n185        191 2022-06-22  3\n186        192 2022-06-27  3\n187        193 2022-06-29  3\n188        194 2022-07-04  3\n189        195 2022-07-06  3\n190        196 2022-07-11  3\n191        197 2022-07-13  3\n192        198 2022-07-18  3\n193        199 2022-07-20  3\n194        200 2022-07-25  3\n195        201 2022-07-27  3\n196        202 2022-08-01  3\n197        203 2022-08-03  3\n198        204 2022-08-08  3\n199        205 2022-08-10  3\n200        206 2022-08-15  3\n201        207 2022-08-17  3\n202        208 2022-08-22  3\n203        209 2022-08-24  3\n204        210 2022-08-29  3\n205        211 2022-08-31  3\n206        212 2022-09-05  3\n207        213 2022-09-07  3\n208        214 2022-09-13  3\n209        215 2022-09-14  3\n210        216 2022-09-19  3\n211        217 2022-09-21  3\n212        218 2022-09-26  3\n213        219 2022-09-28  3\n214        220 2022-10-03  3\n215        221 2022-10-05  3\n216        222 2022-10-10  3\n217        223 2022-10-12  3\n218        224 2022-10-17  3\n219        225 2022-10-19  3\n220        226 2022-10-24  3\n221        227 2022-10-26  3\n222        228 2022-10-31  3\n223        229 2022-11-02  3\n224        230 2022-11-07  3\n225        231 2022-11-09  3\n226        232 2022-11-14  3\n227        233 2022-11-16  3\n228        234 2022-11-21  3\n229        235 2022-11-28  3\n230        236 2022-11-30  3\n231        237 2022-12-05  3\n232        238 2022-12-07  3\n233        239 2022-12-12  3\n234        240 2022-12-14  3\n235        241 2022-12-19  3\n236        242 2022-12-21  3\n237        243 2023-01-04  3\n\n\n\n\nCount observations for each collection date\n\nplant_v2 %&gt;% ggplot(aes(Collection)) + \n  geom_histogram(binwidth = 1) #max should be 3"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#cleaning-and-merging",
    "href": "code/processing/1_initial_cleaning.html#cleaning-and-merging",
    "title": "Raw data processing",
    "section": "Cleaning and merging",
    "text": "Cleaning and merging\n\nqPCR data\n\nSelect for important variables, convert non-detects to NAs\n\n#Select date, collection number, sample id/bio rep, target, and ct\n#Convert Undetermined Cts to NAs\n\n#StepOne N1\nn1_stepone_clean &lt;- n1_stepone_v2 %&gt;% select(c(sample_date, collection_num, sample_id, target, ct)) %&gt;% \n  mutate(ct=as.numeric(ifelse(ct==\"Undetermined\", NA, ct)))\n\n#StepOne N2\nn2_stepone_clean &lt;- n2_stepone_v2 %&gt;% select(c(sample_date, collection_num, sample_id, target, ct)) %&gt;% \n  mutate(ct=as.numeric(ifelse(ct==\"Undetermined\", NA, ct)))\n\n#CFX N1\nn1_cfx_clean &lt;- n1_cfx_v2 %&gt;% select(c(sample_date, collection_num, sample_id, target, ct)) %&gt;% \n  mutate(ct=as.numeric(ifelse(ct==\"Undetermined\", NA, ct)))\n\n#CFX N2\nn2_cfx_clean &lt;- n2_cfx_v2 %&gt;% select(c(sample_date, collection_num, sample_id, target, ct)) %&gt;% \n  mutate(ct=as.numeric(ifelse(ct==\"Undetermined\", NA, ct)))\n\n\n\nBind qPCR NA data sets\n\n#Bind qpcr data\nqpcr_na &lt;- bind_rows(n1_stepone_clean, n2_stepone_clean, n1_cfx_clean, n2_cfx_clean) %&gt;% \n  mutate(\n    date = sample_date,\n    facility=substr(sample_id, 1,2), #first two letters in sample_id is treatment facility ID\n    biological_replicate=substr(sample_id, nchar(sample_id), nchar(sample_id))) %&gt;% #last number in sample_id is the biological rep\n arrange(date, facility, target, biological_replicate) %&gt;% \n  select(date, facility, target, biological_replicate, collection_num, ct)#select necessary variables\n  \n#Save to processed data folder\nsaveRDS(qpcr_na, here(\"data/processed_data/qpcr_na.rds\"))\n\n\n\nCalculate LOD and LOQ for qPCR data\n\n#Determine the LOD and LOQ by plotting the Normal QQ-Plot\nqqnorm.ct.n1.stepone &lt;- qqnorm(n1_stepone_clean$ct, plot.it = T) %&gt;% as.data.frame()\n\n\n\nqqnorm.ct.n2.stepone &lt;- qqnorm(n2_stepone_clean$ct, plot.it = T) %&gt;% as.data.frame()\n\n\n\nqqnorm.ct.n1.cfx &lt;- qqnorm(n1_cfx_clean$ct, plot.it = T) %&gt;% as.data.frame()\n\n\n\nqqnorm.ct.n2.cfx &lt;- qqnorm(n2_cfx_clean$ct, plot.it = T) %&gt;% as.data.frame()\n\n\n\ntiff(filename = \"figures/detection_lims.tiff\", height = 9, width = 8, units = \"in\", res = 600)\n\n#Create function to compute LOD and lOQ\nqqnorm.Explorer.ct &lt;- function(qqnorm.ct){\n  qqnorm.ct &lt;- qqnorm.ct[which(complete.cases(qqnorm.ct)),]\n  qqnorm.ct &lt;- qqnorm.ct[order(qqnorm.ct$x),]\n  qqnorm.ct &lt;- cbind(qqnorm.ct, rbind(NA, qqnorm.ct[-nrow(qqnorm.ct),])) %&gt;% setNames(., nm = c(\"x\", \"y\", \"x-1\", \"y-1\"))\n  qqnorm.ct %&lt;&gt;% mutate(rise = y-`y-1`, run = x-`x-1`) %&gt;% mutate(slope = rise / run)\n  qqnorm.ct$lod &lt;- NA\n  qqnorm.ct$loq &lt;- NA\n  prev.slope &lt;- 1\n  lod.found &lt;- 0\n  for(i in nrow(qqnorm.ct):2){\n    if(lod.found==0){\n      if(qqnorm.ct$slope[i]&lt;1 & prev.slope &lt;1){\n        qqnorm.ct$lod[i] &lt;- 1\n        lod.found &lt;- 1\n      }else{\n        prev.slope &lt;- qqnorm.ct$slope[i]\n      }\n    }\n    if(lod.found==1){\n      if(qqnorm.ct$slope[i]&gt;1){\n        qqnorm.ct$loq[i] &lt;- 1\n        break\n      }else{\n        prev.slope &lt;- qqnorm.ct$slope[i]\n      }\n    }\n  }\n  lod.ct &lt;- qqnorm.ct$y[which(qqnorm.ct$lod==1)]\n  loq.ct &lt;- qqnorm.ct$y[which(qqnorm.ct$loq==1)]\n  return(list(qqnorm.dataset = qqnorm.ct, lod = lod.ct, loq = loq.ct))\n}\n\n#Run function on each data set\nqqnorm.ct.n1.stepone &lt;- qqnorm.Explorer.ct(qqnorm.ct.n1.stepone)\nqqnorm.ct.n2.stepone &lt;- qqnorm.Explorer.ct(qqnorm.ct.n2.stepone)\nqqnorm.ct.n1.cfx &lt;- qqnorm.Explorer.ct(qqnorm.ct.n1.cfx)\nqqnorm.ct.n2.cfx &lt;- qqnorm.Explorer.ct(qqnorm.ct.n2.cfx)\n\n#Save LOD and LOQ for each data set\nn1_stepone_lod &lt;- qqnorm.ct.n1.stepone$lod\nn1_stepone_loq &lt;- qqnorm.ct.n1.stepone$loq\nn2_stepone_lod &lt;- qqnorm.ct.n2.stepone$lod\nn2_stepone_loq &lt;- qqnorm.ct.n2.stepone$loq\n\nn1_cfx_lod &lt;- qqnorm.ct.n1.cfx$lod\nn1_cfx_loq &lt;- qqnorm.ct.n1.cfx$loq\nn2_cfx_lod &lt;- qqnorm.ct.n2.cfx$lod\nn2_cfx_loq &lt;- qqnorm.ct.n2.cfx$loq\n\nn1_stepone_lod\n\n[1] 37.14072\n\nn2_stepone_lod\n\n[1] 37.10763\n\nn1_cfx_lod \n\n[1] 39.93763\n\nn2_cfx_lod\n\n[1] 39.9942\n\n\n\n\nTransform Ct NAs to calculate SARS-CoV-2 copies\n\n#Replace NAs with limit of detection\n#Use standard curve slope for each target to calculate copies per uL per rxn\n\n#StepOne N1\nn1_stepone_clean &lt;- n1_stepone_clean %&gt;% \n  mutate(ct = replace_na(ct, n1_stepone_lod),\n         copy_num_uL_rxn = as.numeric(10^((ct-34.008)/-3.389)))\n\n#StepOne N2\nn2_stepone_clean &lt;- n2_stepone_clean %&gt;% \n  mutate(ct = replace_na(ct, n2_stepone_lod),\n         copy_num_uL_rxn = as.numeric(10^((ct-32.416)/-3.3084)))\n\n#CFX N1\nn1_cfx_clean &lt;- n1_cfx_clean %&gt;% \n  mutate(ct = replace_na(ct, n1_cfx_lod), \n         copy_num_uL_rxn = as.numeric(10^((ct-36.046)/-3.5293)))\n\n#CFX N2\nn2_cfx_clean &lt;- n2_cfx_clean %&gt;% \n  mutate(ct = replace_na(ct, n2_cfx_lod),\n         copy_num_uL_rxn = as.numeric(10^((ct-37.731)/-3.2505)))\n\n\n\nQuick look at Ct distribution\n\n#N1 StepOne\nn1_stepone_clean %&gt;% filter(ct&lt;n1_stepone_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N2 StepOne\nn2_stepone_clean %&gt;% filter(ct&lt;n2_stepone_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N1 CFX\nn1_cfx_clean %&gt;% filter(ct&lt;n1_cfx_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#N2 CFX\nn2_cfx_clean %&gt;% filter(ct&lt;n2_cfx_lod) %&gt;% ggplot(aes(ct)) + geom_histogram()\n\n\n\n#loooooots of non-detects\n\n\n\nBind all qPCR data sets\n\n#Bind qpcr data\nqpcr_all &lt;- bind_rows(n1_stepone_clean, n2_stepone_clean, n1_cfx_clean, n2_cfx_clean) %&gt;% \n  mutate(\n    date = sample_date,\n    facility=substr(sample_id, 1,2), #first two letters in sample_id is treatment facility ID\n    biological_replicate=substr(sample_id, nchar(sample_id), nchar(sample_id))) %&gt;% #last number in sample_id is the biological rep\n arrange(date, facility, target, biological_replicate) %&gt;% \n  select(date, facility, target, biological_replicate, collection_num, ct, copy_num_uL_rxn)#select necessary variables\n  \n#Save to processed data folder\nsaveRDS(qpcr_all, here(\"data/processed_data/qpcr_all.rds\"))\n\n\n\n\nCombine plant and qPCR data sets\n\n#Change plant variable names to match qPCR names, remove notes variable, convert millions of gallons to liters\nplant_v2&lt;- plant_v2 %&gt;% rename(collection_num = Collection, facility = wrf) %&gt;% \n  select(!notes) %&gt;% \n  mutate(influent_flow_L = influent_flow_mg*1e6*231*(0.0254^3)*1000)\n\n#Select qPCR variables to merge\n#qpcr_all &lt;- qpcr_all %&gt;% select(!date)\n\n#Merge and mutate\nqpcr_plant_all &lt;- merge(qpcr_all, plant_v2, by = c(\"collection_num\", \"facility\", \"date\"), all = T) %&gt;% \n  mutate(facility = as.factor(facility), #code each facility as a factor\n         facility = recode(facility, NO = \"A\", MI = \"B\", CC = \"C\"), #de-identify treatment facility\n         facility = ordered(facility, levels = c(\"A\", \"B\", \"C\")), #set facility factor levels\n         copy_num_L = copy_num_uL_rxn*20/5*60/280*1000*1000,\n         viral_load = copy_num_L*influent_flow_L) #transform copies per uL of reaction to copies per liter\n\n#Save to processed data folder\nsaveRDS(qpcr_plant_all, here(\"data/processed_data/qpcr_plant_all.rds\"))\n\n\n\nQuick look at WBE data\n\n#Filter for correct date range, then visualize observations for each collection\nqpcr_plant_all %&gt;% filter(between(collection_num, 7, 243)) %&gt;% \n  ggplot(aes(collection_num)) +\n  geom_bar()\n\n\n\n\n\n#which observations are low?\nqpcr_plant_all %&gt;% count(collection_num) %&gt;% \n  filter(between(collection_num, 7, 243), n &lt; 10)\n\n  collection_num n\n1             40 3\n2             94 3\n3            135 3\n4            213 3\n\n\n\n\nCombine DPH COVID data sets\n\ncovid &lt;- full_join(\n  covid_symptom%&gt;%\n    select(cases.symptom.onset=cases, date=symptom.date), \n  covid_case%&gt;%\n    select(cases.reported=cases, date=report_date), \n  by = \"date\"\n) %&gt;% \n  full_join(\n    covid_testing%&gt;%\n      rename(date=collection_date), \n    by=\"date\"\n  ) %&gt;%\n  select(date, cases.symptom.onset, cases.reported, pcr_tests, pcr_pos, pcr_pos_7dma, pcr_pos_14dma) %&gt;% \n\n  mutate(prop_pos = pcr_pos/pcr_tests)\n\n#Save to processed data folder\nsaveRDS(covid, here(\"data/processed_data/all_covid_combined.rds\"))\ncovid\n\n# A tibble: 1,090 × 8\n   date       cases.symptom.on…¹ cases…² pcr_t…³ pcr_pos pcr_p…⁴ pcr_p…⁵ prop_…⁶\n   &lt;date&gt;                  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 2020-02-01                  0       0       0       0      NA      NA     NaN\n 2 2020-02-02                  0       0       0       0      NA      NA     NaN\n 3 2020-02-03                  0       0       0       0      NA      NA     NaN\n 4 2020-02-04                  0       0       0       0      NA      NA     NaN\n 5 2020-02-05                  0       0       0       0      NA      NA     NaN\n 6 2020-02-06                  0       0       0       0      NA      NA     NaN\n 7 2020-02-07                  0       0       0       0       0      NA     NaN\n 8 2020-02-08                  0       0       0       0       0      NA     NaN\n 9 2020-02-09                  0       0       0       0       0      NA     NaN\n10 2020-02-10                  1       0       0       0       0      NA     NaN\n# … with 1,080 more rows, and abbreviated variable names ¹​cases.symptom.onset,\n#   ²​cases.reported, ³​pcr_tests, ⁴​pcr_pos_7dma, ⁵​pcr_pos_14dma, ⁶​prop_pos"
  },
  {
    "objectID": "code/processing/1_initial_cleaning.html#filter-hospitalization-data",
    "href": "code/processing/1_initial_cleaning.html#filter-hospitalization-data",
    "title": "Raw data processing",
    "section": "Filter hospitalization data",
    "text": "Filter hospitalization data\nFilter for state of GA, city of Athens, and for appropriate dates\n\n#athens_hospitalizations &lt;- hospitalization %&gt;% \n  #filter(state==\"GA\", city==\"ATHENS\", between(collection_week, as.Date(\"2020-06-28\"), as.Date(\"2023-01-08\")))\n\n#Save to processed data folder\n#saveRDS(athens_hospitalizations, here(\"data/processed_data/athens_hospitalizations.rds\"))\n\n\nCombine WBE and COVID data sets\n\nwbe_covid &lt;- merge(qpcr_plant_all, covid, by = \"date\", all = T) %&gt;% \n  filter(between(date, as.Date(\"2020-06-30\"), as.Date(\"2023-01-04\")))\n\n#I didn't save this because I probably won't use it, we can combine later in script 2"
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me!",
    "section": "",
    "text": "University of Georgia Environmental Health Science\n\n\n\nErin Lipp\nTravis Glenn\n\n\n\nAndreas Handel"
  },
  {
    "objectID": "code/processing/2_preprocessing.html",
    "href": "code/processing/2_preprocessing.html",
    "title": "Pre-processing",
    "section": "",
    "text": "This pre-processing script does the following:\n\nWBE technical replicates are averaged\nViral load is summed across WWTPs per date per target\nViral load is averaged across targets (N1 and N2) per date\nWW qPCR assay detection frequency is calculated\n7 day moving average is calculated for all variables of interest\nWBE and COVID data are combined and weekly averages are calculated\nHospitalization data will also be added in the future"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#info",
    "href": "code/processing/2_preprocessing.html#info",
    "title": "Pre-processing",
    "section": "",
    "text": "This pre-processing script does the following:\n\nWBE technical replicates are averaged\nViral load is summed across WWTPs per date per target\nViral load is averaged across targets (N1 and N2) per date\nWW qPCR assay detection frequency is calculated\n7 day moving average is calculated for all variables of interest\nWBE and COVID data are combined and weekly averages are calculated\nHospitalization data will also be added in the future"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#load-packages",
    "href": "code/processing/2_preprocessing.html#load-packages",
    "title": "Pre-processing",
    "section": "Load packages",
    "text": "Load packages\n\nknitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fpp3)\nlibrary(skimr)\nlibrary(ggpubr)"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#load-data",
    "href": "code/processing/2_preprocessing.html#load-data",
    "title": "Pre-processing",
    "section": "Load data",
    "text": "Load data\n\n#WBE file from processing script\nwbe &lt;- read_rds(here(\"data/processed_data/qpcr_plant_all.rds\"))\n\n#COVID file from processing script\ncovid &lt;- read_rds(here(\"data/processed_data/all_covid_combined.rds\"))\n\n#Hospitalization data from processing script\nhospital &lt;- read_rds(here(\"data/processed_data/athens_hospitalizations.rds\"))\n\n#Load qPCR file with ct NAs from processing script\nqpcr_na &lt;- read_rds(here(\"data/processed_data/qpcr_na.rds\"))"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#a-wbe-wrangling",
    "href": "code/processing/2_preprocessing.html#a-wbe-wrangling",
    "title": "Pre-processing",
    "section": "A) WBE Wrangling",
    "text": "A) WBE Wrangling\n\n1. More cleaning\n\n#Remove observations when Cts = NA, this means that collection is missing or not part of the surveillance study\nwbe &lt;- wbe %&gt;% na.omit(ct)\n\n#Check for NAs in the rest of the data\nskim(wbe) #yay nothing is missing\n\n\nData summary\n\n\nName\nwbe\n\n\nNumber of rows\n20556\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nDate\n1\n\n\nfactor\n1\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntarget\n0\n1\n2\n2\n0\n2\n0\n\n\nbiological_replicate\n0\n1\n1\n1\n0\n7\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n2020-06-30\n2023-01-04\n2021-12-20\n230\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nfacility\n0\n1\nTRUE\n3\nA: 6893, B: 6872, C: 6791\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncollection_num\n0\n1\n1.378800e+02\n6.259000e+01\n7.000000e+00\n8.900000e+01\n1.400000e+02\n1.910000e+02\n2.430000e+02\n▃▇▇▇▇\n\n\nct\n0\n1\n3.807000e+01\n1.500000e+00\n3.102000e+01\n3.711000e+01\n3.766000e+01\n3.994000e+01\n4.000000e+01\n▁▁▂▇▇\n\n\ncopy_num_uL_rxn\n0\n1\n4.300000e-01\n8.700000e-01\n1.000000e-02\n1.200000e-01\n2.000000e-01\n5.200000e-01\n3.485000e+01\n▇▁▁▁▁\n\n\ninfluent_flow_mg\n0\n1\n3.690000e+00\n1.770000e+00\n1.280000e+00\n1.830000e+00\n3.550000e+00\n5.180000e+00\n1.311000e+01\n▇▆▁▁▁\n\n\ninfluent_tss_mg_l\n0\n1\n2.474500e+02\n1.690100e+02\n4.800000e+00\n1.480000e+02\n2.080000e+02\n2.840000e+02\n1.380000e+03\n▇▂▁▁▁\n\n\ninfluent_flow_L\n0\n1\n1.398262e+07\n6.684690e+06\n4.845327e+06\n6.927304e+06\n1.343821e+07\n1.960843e+07\n4.962675e+07\n▇▆▁▁▁\n\n\ncopy_num_L\n0\n1\n3.697209e+05\n7.458327e+05\n8.616570e+03\n1.020177e+05\n1.725005e+05\n4.451149e+05\n2.987138e+07\n▇▁▁▁▁\n\n\nviral_load\n0\n1\n4.923052e+12\n9.907915e+12\n8.344504e+10\n1.031717e+12\n2.331721e+12\n5.253990e+12\n3.595800e+14\n▇▁▁▁▁\n\n\n\n\n#Count observations for each date/facility/target/collection\nwbe_count &lt;- wbe %&gt;% count(date,facility,target,collection_num) #max is either 9 or 18\nhead(wbe_count, n = 10)\n\n         date facility target collection_num  n\n1  2020-06-30        A     N1              7 18\n2  2020-06-30        A     N2              7 18\n3  2020-06-30        B     N1              7 12\n4  2020-06-30        B     N2              7 12\n5  2020-06-30        C     N1              7  3\n6  2020-06-30        C     N2              7  3\n7  2020-07-07        A     N1              8  9\n8  2020-07-07        A     N2              8  9\n9  2020-07-07        B     N1              8  6\n10 2020-07-07        B     N2              8  6\n\n\n\n\n2. Average qPCR replicates\n\n#group, then take the average copies per liter and standard deviation\nwbe_avg &lt;- wbe %&gt;% \n  group_by(date,facility,target,collection_num) %&gt;% \n  summarize(avg_copy_L = mean(copy_num_L),\n            sd_copy_L = sd(copy_num_L), \n            influent_flow_L = mean(influent_flow_L),\n            avg_viral_load = mean(viral_load),\n            sd_viral_load = sd(viral_load),\n            avg_ct = mean(ct),\n            sd_ct = sd(ct))%&gt;% \n  ungroup()\nhead(wbe_avg, n=10)\n\n# A tibble: 10 × 11\n   date       facility target collecti…¹ avg_c…² sd_co…³ influ…⁴ avg_v…⁵ sd_vi…⁶\n   &lt;date&gt;     &lt;ord&gt;    &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 2020-06-30 A        N1              7 166962. 146733.  1.87e7 3.13e12 2.75e12\n 2 2020-06-30 A        N2              7  49504.  50747.  1.87e7 9.28e11 9.51e11\n 3 2020-06-30 B        N1              7 110644.  27866.  1.14e7 1.26e12 3.19e11\n 4 2020-06-30 B        N2              7  33968.  13754.  1.14e7 3.88e11 1.57e11\n 5 2020-06-30 C        N1              7 102018.      0   6.17e6 6.29e11 0      \n 6 2020-06-30 C        N2              7  32731.      0   6.17e6 2.02e11 0      \n 7 2020-07-07 A        N1              8 102018.      0   2.10e7 2.15e12 0      \n 8 2020-07-07 A        N2              8  34333.   3727.  2.10e7 7.23e11 7.84e10\n 9 2020-07-07 B        N1              8 118649.  40738.  1.29e7 1.53e12 5.26e11\n10 2020-07-07 B        N2              8  32731.      0   1.29e7 4.22e11 0      \n# … with 2 more variables: avg_ct &lt;dbl&gt;, sd_ct &lt;dbl&gt;, and abbreviated variable\n#   names ¹​collection_num, ²​avg_copy_L, ³​sd_copy_L, ⁴​influent_flow_L,\n#   ⁵​avg_viral_load, ⁶​sd_viral_load\n\n\n\n\n3. Sum Viral Load across WWTPs\n\nwbe_county_avg &lt;- wbe_avg %&gt;% \n  group_by(date, collection_num, target) %&gt;% \n  summarize(viral_load = sum(avg_viral_load)) %&gt;% #sum across WWTPs for each target\n  ungroup()\n\nhead(wbe_county_avg, n=10)\n\n# A tibble: 10 × 4\n   date       collection_num target viral_load\n   &lt;date&gt;              &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1 2020-06-30              7 N1        5.02e12\n 2 2020-06-30              7 N2        1.52e12\n 3 2020-07-07              8 N1        4.39e12\n 4 2020-07-07              8 N2        1.42e12\n 5 2020-07-14              9 N1        2.99e12\n 6 2020-07-14              9 N2        1.55e12\n 7 2020-07-21             10 N1        6.50e12\n 8 2020-07-21             10 N2        2.61e12\n 9 2020-07-28             11 N1        5.57e12\n10 2020-07-28             11 N2        1.86e12\n\n\n\n\n4. Move N1 and N2 to distinct columns, then calculate average\n\navg_viral_load &lt;- wbe_county_avg %&gt;% \n  group_by(date) %&gt;% \n  summarize(avg_vl = mean(viral_load))\n\nwbe_vl_final &lt;- wbe_county_avg %&gt;% \n  pivot_wider(names_from = target, values_from = viral_load) %&gt;% \n  rename(n1_vl = N1, n2_vl = N2)\n\nwbe_vl_final &lt;- wbe_vl_final %&gt;% full_join(avg_viral_load, wbe_final, by = \"date\")\nhead(wbe_vl_final, n=10)\n\n# A tibble: 10 × 5\n   date       collection_num   n1_vl   n2_vl  avg_vl\n   &lt;date&gt;              &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 2020-06-30              7 5.02e12 1.52e12 3.27e12\n 2 2020-07-07              8 4.39e12 1.42e12 2.91e12\n 3 2020-07-14              9 2.99e12 1.55e12 2.27e12\n 4 2020-07-21             10 6.50e12 2.61e12 4.56e12\n 5 2020-07-28             11 5.57e12 1.86e12 3.71e12\n 6 2020-08-04             12 4.20e12 1.35e12 2.78e12\n 7 2020-08-11             13 4.08e12 1.24e12 2.66e12\n 8 2020-08-18             14 5.18e12 1.65e12 3.41e12\n 9 2020-08-25             15 5.68e12 1.58e12 3.63e12\n10 2020-09-01             16 8.63e12 2.94e12 5.78e12\n\n\n\n\n5. Calculate qPCR % Pos\nTechnical replicates per bio rep/target/facility/date\n\ndetection_tr &lt;- qpcr_na %&gt;% \n  select(c(date,facility,target,biological_replicate,ct)) %&gt;% \n        group_by(date,facility,target,biological_replicate) %&gt;% \n        summarize(n = n(), \n                  n_miss = sum(is.na(ct)),\n                  n_pos = n-n_miss)\nhead(detection_tr,n=10)\n\n# A tibble: 10 × 7\n# Groups:   date, facility, target [5]\n   date       facility target biological_replicate     n n_miss n_pos\n   &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;                &lt;int&gt;  &lt;int&gt; &lt;int&gt;\n 1 2020-06-30 CC       N1     C                        3      3     0\n 2 2020-06-30 CC       N2     C                        3      3     0\n 3 2020-06-30 MI       N1     A                        3      2     1\n 4 2020-06-30 MI       N1     B                        3      3     0\n 5 2020-06-30 MI       N1     C                        6      5     1\n 6 2020-06-30 MI       N2     A                        3      3     0\n 7 2020-06-30 MI       N2     B                        3      3     0\n 8 2020-06-30 MI       N2     C                        6      4     2\n 9 2020-06-30 NO       N1     A                        6      5     1\n10 2020-06-30 NO       N1     B                        3      3     0\n\n\nTechnical reps per target/facility/date\n\ndetection_target &lt;- qpcr_na %&gt;% \n  select(c(date,facility,target,biological_replicate,ct)) %&gt;% \n        group_by(date,facility,target) %&gt;% \n        summarize(n = n(), \n                  n_miss = sum(is.na(ct)),\n                  n_pos = n-n_miss,\n                  pos_rate = (n_pos/n)*100) %&gt;% \n  ungroup()\n\ndetection_target_wide &lt;- detection_target %&gt;% pivot_wider(names_from = target, values_from = c(n, n_miss, n_pos, pos_rate))\n\nhead(detection_target_wide, n=10)\n\n# A tibble: 10 × 10\n   date       facility  n_N1  n_N2 n_miss_N1 n_miss_N2 n_pos_N1 n_pos_N2 pos_r…¹\n   &lt;date&gt;     &lt;chr&gt;    &lt;int&gt; &lt;int&gt;     &lt;int&gt;     &lt;int&gt;    &lt;int&gt;    &lt;int&gt;   &lt;dbl&gt;\n 1 2020-06-30 CC           3     3         3         3        0        0     0  \n 2 2020-06-30 MI          12    12        10        10        2        2    16.7\n 3 2020-06-30 NO          18    18        12        13        6        5    33.3\n 4 2020-07-07 CC           6     6         5         4        1        2    16.7\n 5 2020-07-07 MI           6     6         5         6        1        0    16.7\n 6 2020-07-07 NO           9     9         9         7        0        2     0  \n 7 2020-07-14 MI           3     6         3         4        0        2     0  \n 8 2020-07-14 NO           9     9         8         5        1        4    11.1\n 9 2020-07-21 CC           6     6         3         4        3        2    50  \n10 2020-07-21 MI           9     6         6         1        3        5    33.3\n# … with 1 more variable: pos_rate_N2 &lt;dbl&gt;, and abbreviated variable name\n#   ¹​pos_rate_N1\n\n\nTechnical reps per facility/date\n\ndetection_facility &lt;- qpcr_na %&gt;% \n  select(c(date,facility,target,biological_replicate,ct)) %&gt;% \n        group_by(date,facility) %&gt;% \n        summarize(n = n(), \n                  n_miss = sum(is.na(ct)),\n                  n_pos = n-n_miss,\n                  pos_rate = (n_pos/n)*100)\n\nhead(detection_facility, n=10)\n\n# A tibble: 10 × 6\n# Groups:   date [4]\n   date       facility     n n_miss n_pos pos_rate\n   &lt;date&gt;     &lt;chr&gt;    &lt;int&gt;  &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;\n 1 2020-06-30 CC           6      6     0     0   \n 2 2020-06-30 MI          24     20     4    16.7 \n 3 2020-06-30 NO          36     25    11    30.6 \n 4 2020-07-07 CC          12      9     3    25   \n 5 2020-07-07 MI          12     11     1     8.33\n 6 2020-07-07 NO          18     16     2    11.1 \n 7 2020-07-14 MI           9      7     2    22.2 \n 8 2020-07-14 NO          18     13     5    27.8 \n 9 2020-07-21 CC          12      7     5    41.7 \n10 2020-07-21 MI          15      7     8    53.3 \n\n\nTechnical reps per date (targets included)\n\ndetection_date &lt;- qpcr_na %&gt;% \n  select(c(date,facility,target,biological_replicate,ct)) %&gt;% \n        group_by(date,target) %&gt;% #summarize at county level for both targets\n        summarize(n_reps = n(), #count number of technical reps\n                  n_miss = sum(is.na(ct)), #count number of non detects\n                  n_pos = n_reps-n_miss, #count number of detects\n                  pos_rate = (n_pos/n_reps)*100) %&gt;% #calculate detection frequency\n  ungroup() %&gt;% \n  pivot_wider(names_from = target, values_from=c(n_reps, pos_rate, n_miss, n_pos)) %&gt;%\n  #put N1 and N2 in separate columns\n  mutate(n_reps=n_reps_N1+n_reps_N2, #add reps from both targets\n         n_miss=n_miss_N1+n_miss_N2, #add nondetects from both targets\n         n_pos=n_reps-n_miss, #add detects from both targets\n         avg_pos_rate = (n_pos/n_reps)*100) %&gt;% #average detection freq across targets\n  select(!c(n_pos,n_miss,n_pos_N1,n_miss_N1,n_pos_N2,n_miss_N2)) #dump these\n\nhead(detection_date,n=10)\n\n# A tibble: 10 × 7\n   date       n_reps_N1 n_reps_N2 pos_rate_N1 pos_rate_N2 n_reps avg_pos_rate\n   &lt;date&gt;         &lt;int&gt;     &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;  &lt;int&gt;        &lt;dbl&gt;\n 1 2020-06-30        33        33       24.2        21.2      66        22.7 \n 2 2020-07-07        21        21        9.52       19.0      42        14.3 \n 3 2020-07-14        12        15        8.33       40        27        25.9 \n 4 2020-07-21        21        18       28.6        55.6      39        41.0 \n 5 2020-07-28        18        18       22.2        38.9      36        30.6 \n 6 2020-08-04        18        18        0           5.56     36         2.78\n 7 2020-08-11        18        18       11.1         5.56     36         8.33\n 8 2020-08-18        18        18       27.8        55.6      36        41.7 \n 9 2020-08-25        18        18       27.8        16.7      36        22.2 \n10 2020-09-01        18        18       38.9        50        36        44.4 \n\n\n\n\n6. Smoosh wbe data set with %pos data\n\nwbe_daily &lt;- left_join(wbe_vl_final,detection_date, by=\"date\") %&gt;% \n  mutate(week = yearweek(date))\n\nhead(wbe_daily,n=10)\n\n# A tibble: 10 × 12\n   date       collecti…¹   n1_vl   n2_vl  avg_vl n_rep…² n_rep…³ pos_r…⁴ pos_r…⁵\n   &lt;date&gt;          &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 2020-06-30          7 5.02e12 1.52e12 3.27e12      33      33   24.2    21.2 \n 2 2020-07-07          8 4.39e12 1.42e12 2.91e12      21      21    9.52   19.0 \n 3 2020-07-14          9 2.99e12 1.55e12 2.27e12      12      15    8.33   40   \n 4 2020-07-21         10 6.50e12 2.61e12 4.56e12      21      18   28.6    55.6 \n 5 2020-07-28         11 5.57e12 1.86e12 3.71e12      18      18   22.2    38.9 \n 6 2020-08-04         12 4.20e12 1.35e12 2.78e12      18      18    0       5.56\n 7 2020-08-11         13 4.08e12 1.24e12 2.66e12      18      18   11.1     5.56\n 8 2020-08-18         14 5.18e12 1.65e12 3.41e12      18      18   27.8    55.6 \n 9 2020-08-25         15 5.68e12 1.58e12 3.63e12      18      18   27.8    16.7 \n10 2020-09-01         16 8.63e12 2.94e12 5.78e12      18      18   38.9    50   \n# … with 3 more variables: n_reps &lt;int&gt;, avg_pos_rate &lt;dbl&gt;, week &lt;week&gt;, and\n#   abbreviated variable names ¹​collection_num, ²​n_reps_N1, ³​n_reps_N2,\n#   ⁴​pos_rate_N1, ⁵​pos_rate_N2\n\nsaveRDS(wbe_daily,here(\"data/processed_data/wbe_county_avg.rds\"))\n\n\n\n7. Calculate WBE 7-DMA\n\nwbe_7dma &lt;- wbe_daily %&gt;% mutate(\n  vl_7dma=stats::filter(avg_vl,filter=rep(1/7,7),method= 'convolution',sides=1),\n  vl_n1_7dma=stats::filter(n1_vl,filter=rep(1/7,7),method= 'convolution',sides=1),\n  vl_n2_7dma=stats::filter(n2_vl,filter=rep(1/7,7),method= 'convolution',sides=1),\n  pr_7dma=stats::filter(avg_pos_rate,filter=rep(1/7,7),method= 'convolution',sides=1),\n  pr_n1_7dma=stats::filter(pos_rate_N1,filter=rep(1/7,7),method= 'convolution',sides=1),\n  pr_n2_7dma=stats::filter(pos_rate_N2,filter=rep(1/7,7),method= 'convolution',sides=1))\nhead(wbe_7dma, n=10)\n\n# A tibble: 10 × 18\n   date       collecti…¹   n1_vl   n2_vl  avg_vl n_rep…² n_rep…³ pos_r…⁴ pos_r…⁵\n   &lt;date&gt;          &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 2020-06-30          7 5.02e12 1.52e12 3.27e12      33      33   24.2    21.2 \n 2 2020-07-07          8 4.39e12 1.42e12 2.91e12      21      21    9.52   19.0 \n 3 2020-07-14          9 2.99e12 1.55e12 2.27e12      12      15    8.33   40   \n 4 2020-07-21         10 6.50e12 2.61e12 4.56e12      21      18   28.6    55.6 \n 5 2020-07-28         11 5.57e12 1.86e12 3.71e12      18      18   22.2    38.9 \n 6 2020-08-04         12 4.20e12 1.35e12 2.78e12      18      18    0       5.56\n 7 2020-08-11         13 4.08e12 1.24e12 2.66e12      18      18   11.1     5.56\n 8 2020-08-18         14 5.18e12 1.65e12 3.41e12      18      18   27.8    55.6 \n 9 2020-08-25         15 5.68e12 1.58e12 3.63e12      18      18   27.8    16.7 \n10 2020-09-01         16 8.63e12 2.94e12 5.78e12      18      18   38.9    50   \n# … with 9 more variables: n_reps &lt;int&gt;, avg_pos_rate &lt;dbl&gt;, week &lt;week&gt;,\n#   vl_7dma &lt;dbl&gt;, vl_n1_7dma &lt;dbl&gt;, vl_n2_7dma &lt;dbl&gt;, pr_7dma &lt;dbl&gt;,\n#   pr_n1_7dma &lt;dbl&gt;, pr_n2_7dma &lt;dbl&gt;, and abbreviated variable names\n#   ¹​collection_num, ²​n_reps_N1, ³​n_reps_N2, ⁴​pos_rate_N1, ⁵​pos_rate_N2\n\nsaveRDS(wbe_7dma,here(\"data/processed_data/wbe_7dma.rds\"))"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#b-covid-wrangling",
    "href": "code/processing/2_preprocessing.html#b-covid-wrangling",
    "title": "Pre-processing",
    "section": "B) COVID Wrangling",
    "text": "B) COVID Wrangling\n\n1. Subset COVID dates\n\ncovid_daily &lt;- covid %&gt;% \n  filter(between(date, as.Date(\"2020-06-30\"), as.Date(\"2023-01-04\"))) %&gt;%  #filter for surveillance time series\n  mutate(date = as_date(date),\n         week = yearweek(date))\n\nhead(covid_daily,n=10)\n\n# A tibble: 10 × 9\n   date       cases.s…¹ cases…² pcr_t…³ pcr_pos pcr_p…⁴ pcr_p…⁵ prop_…⁶     week\n   &lt;date&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;week&gt;\n 1 2020-06-30        55      18     551      66    11       9.5  0.120  2020 W27\n 2 2020-07-01        59      27     614      67    11       9.9  0.109  2020 W27\n 3 2020-07-02        39      47     559      60    11.2    10.3  0.107  2020 W27\n 4 2020-07-03        31      39     255      32    11.5    10.6  0.125  2020 W27\n 5 2020-07-04        20      22      34       7    12      11.4  0.206  2020 W27\n 6 2020-07-05        18      37     106      10    12      11.5  0.0943 2020 W27\n 7 2020-07-06        53      17     612      93    13.1    11.8  0.152  2020 W28\n 8 2020-07-07        67      35     649      82    13.1    12.1  0.126  2020 W28\n 9 2020-07-08        43      43     661      60    12.9    12    0.0908 2020 W28\n10 2020-07-09        52      35     702      78    12.9    12.1  0.111  2020 W28\n# … with abbreviated variable names ¹​cases.symptom.onset, ²​cases.reported,\n#   ³​pcr_tests, ⁴​pcr_pos_7dma, ⁵​pcr_pos_14dma, ⁶​prop_pos\n\n\n\n\n2. Calculate Case 7-DMA\n\ncovid_7dma &lt;- covid_daily %&gt;% mutate(\n symptom_onset_7dma=stats::filter(cases.symptom.onset,filter=rep(1/7,7),method= 'convolution',sides=1),\n case_report_7dma=stats::filter(cases.reported,filter=rep(1/7,7),method= 'convolution',sides=1),\n case_pcr_pos_7dma=stats::filter(pcr_pos,filter=rep(1/7,7),method= 'convolution',sides=2),\n case_prop_pos_7dma=stats::filter(prop_pos,filter=rep(1/7,7),method= 'convolution',sides=1))\n\nhead(covid_7dma,n=10)\n\n# A tibble: 10 × 13\n   date       cases.s…¹ cases…² pcr_t…³ pcr_pos pcr_p…⁴ pcr_p…⁵ prop_…⁶     week\n   &lt;date&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;week&gt;\n 1 2020-06-30        55      18     551      66    11       9.5  0.120  2020 W27\n 2 2020-07-01        59      27     614      67    11       9.9  0.109  2020 W27\n 3 2020-07-02        39      47     559      60    11.2    10.3  0.107  2020 W27\n 4 2020-07-03        31      39     255      32    11.5    10.6  0.125  2020 W27\n 5 2020-07-04        20      22      34       7    12      11.4  0.206  2020 W27\n 6 2020-07-05        18      37     106      10    12      11.5  0.0943 2020 W27\n 7 2020-07-06        53      17     612      93    13.1    11.8  0.152  2020 W28\n 8 2020-07-07        67      35     649      82    13.1    12.1  0.126  2020 W28\n 9 2020-07-08        43      43     661      60    12.9    12    0.0908 2020 W28\n10 2020-07-09        52      35     702      78    12.9    12.1  0.111  2020 W28\n# … with 4 more variables: symptom_onset_7dma &lt;dbl&gt;, case_report_7dma &lt;dbl&gt;,\n#   case_pcr_pos_7dma &lt;dbl&gt;, case_prop_pos_7dma &lt;dbl&gt;, and abbreviated variable\n#   names ¹​cases.symptom.onset, ²​cases.reported, ³​pcr_tests, ⁴​pcr_pos_7dma,\n#   ⁵​pcr_pos_14dma, ⁶​prop_pos\n\nsaveRDS(covid_7dma,here(\"data/processed_data/covid_7dma.rds\"))"
  },
  {
    "objectID": "code/processing/2_preprocessing.html#c-combine-wbe-covid",
    "href": "code/processing/2_preprocessing.html#c-combine-wbe-covid",
    "title": "Pre-processing",
    "section": "C) Combine WBE & COVID",
    "text": "C) Combine WBE & COVID\n\ncovid_wbe_7dma &lt;- left_join(wbe_7dma, covid_7dma, by = c(\"week\",\"date\"))\ncovid_wbe_7dma_weekly &lt;- covid_wbe_7dma %&gt;% \nselect(c(date,week,n1_vl,n2_vl,avg_vl,vl_n1_7dma,vl_n2_7dma,vl_7dma,\n          n_reps_N1,n_reps_N2,n_reps,pos_rate_N1,pos_rate_N2,avg_pos_rate,\n          pr_n1_7dma,pr_n2_7dma,pr_7dma,\n          cases.symptom.onset,symptom_onset_7dma,cases.reported,case_report_7dma,\n          pcr_tests,pcr_pos,pcr_pos_7dma,case_pcr_pos_7dma,pcr_pos_14dma,\n          prop_pos, case_prop_pos_7dma)) %&gt;% \n  group_by(week) %&gt;% \n  summarize_if(is.numeric, mean, na.rm = TRUE) %&gt;% \n  ungroup() %&gt;% \n  as_tsibble(index = \"week\")\n\nhead(covid_wbe_7dma_weekly,n=10)\n\n# A tsibble: 10 x 27 [1W]\n       week   n1_vl   n2_vl  avg_vl vl_n1_7dma vl_n2_7dma   vl_7dma n_reps_N1\n     &lt;week&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 2020 W27 5.02e12 1.52e12 3.27e12  NaN        NaN       NaN              33\n 2 2020 W28 4.39e12 1.42e12 2.91e12  NaN        NaN       NaN              21\n 3 2020 W29 2.99e12 1.55e12 2.27e12  NaN        NaN       NaN              12\n 4 2020 W30 6.50e12 2.61e12 4.56e12  NaN        NaN       NaN              21\n 5 2020 W31 5.57e12 1.86e12 3.71e12  NaN        NaN       NaN              18\n 6 2020 W32 4.20e12 1.35e12 2.78e12  NaN        NaN       NaN              18\n 7 2020 W33 4.08e12 1.24e12 2.66e12    4.68e12    1.65e12   3.16e12        18\n 8 2020 W34 5.18e12 1.65e12 3.41e12    4.70e12    1.67e12   3.18e12        18\n 9 2020 W35 5.68e12 1.58e12 3.63e12    4.89e12    1.69e12   3.29e12        18\n10 2020 W36 8.63e12 2.94e12 5.78e12    5.69e12    1.89e12   3.79e12        18\n# … with 19 more variables: n_reps_N2 &lt;dbl&gt;, n_reps &lt;dbl&gt;, pos_rate_N1 &lt;dbl&gt;,\n#   pos_rate_N2 &lt;dbl&gt;, avg_pos_rate &lt;dbl&gt;, pr_n1_7dma &lt;dbl&gt;, pr_n2_7dma &lt;dbl&gt;,\n#   pr_7dma &lt;dbl&gt;, cases.symptom.onset &lt;dbl&gt;, symptom_onset_7dma &lt;dbl&gt;,\n#   cases.reported &lt;dbl&gt;, case_report_7dma &lt;dbl&gt;, pcr_tests &lt;dbl&gt;,\n#   pcr_pos &lt;dbl&gt;, pcr_pos_7dma &lt;dbl&gt;, case_pcr_pos_7dma &lt;dbl&gt;,\n#   pcr_pos_14dma &lt;dbl&gt;, prop_pos &lt;dbl&gt;, case_prop_pos_7dma &lt;dbl&gt;\n\nsaveRDS(covid_wbe_7dma_weekly,here(\"data/processed_data/covid_wbe_7dma_weekly.rds\"))"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html",
    "href": "code/analysis/3_exploratory_timeseries.html",
    "title": "Exploratory - Time series",
    "section": "",
    "text": "knitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fpp3)"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html#load-packages",
    "href": "code/analysis/3_exploratory_timeseries.html#load-packages",
    "title": "Exploratory - Time series",
    "section": "",
    "text": "knitr::opts_chunk$set(message=F)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fpp3)"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html#load-data",
    "href": "code/analysis/3_exploratory_timeseries.html#load-data",
    "title": "Exploratory - Time series",
    "section": "Load data",
    "text": "Load data\n\ndata &lt;- readRDS(here(\"data/processed_data/covid_wbe_7dma_weekly.rds\"))\n#from pre_processing script"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html#look-at-time-series",
    "href": "code/analysis/3_exploratory_timeseries.html#look-at-time-series",
    "title": "Exploratory - Time series",
    "section": "Look at time series",
    "text": "Look at time series\n\n1. Viral Load\n\ndata %&gt;% na.omit() %&gt;% autoplot(log10(vl_7dma)) #smoothed avg viral load\n\n\n\ndata %&gt;% na.omit() %&gt;% autoplot(log10(avg_vl)) #non-smoothed avg viral load\n\n\n\n\n\n\n2. qPCR positivity rate\n\ndata %&gt;% na.omit() %&gt;% autoplot(avg_pos_rate) #non-smoothed\n\n\n\ndata %&gt;% na.omit() %&gt;% autoplot(pr_7dma) #smoothed\n\n\n\n\n\n\n3. Case symptom onset\n\ndata %&gt;% na.omit() %&gt;% autoplot(cases.symptom.onset) #non-smoothed\n\n\n\ndata %&gt;% na.omit() %&gt;% autoplot(symptom_onset_7dma) #smoothed\n\n\n\n\n\n\n4. Cases reported\n\ndata %&gt;% na.omit() %&gt;% autoplot(cases.reported) #non-smoothed\n\n\n\ndata %&gt;% na.omit() %&gt;% autoplot(case_report_7dma) #smoothed\n\n\n\n\n\n\n5. Case test positives\n\ndata %&gt;% na.omit() %&gt;% autoplot(pcr_pos) #non-smoothed\n\n\n\ndata %&gt;% na.omit() %&gt;% autoplot(case_pcr_pos_7dma) #smoothed by me\n\n\n\ndata %&gt;% na.omit() %&gt;% autoplot(pcr_pos_7dma) #smoothed by DPH\n\n\n\n\n\n\n6. Case test positivity rate\n\ndata %&gt;% na.omit() %&gt;% autoplot(prop_pos) #non-smoothed\n\n\n\ndata %&gt;% na.omit() %&gt;% autoplot(case_prop_pos_7dma) #smoothed\n\n\n\n\n\n\n7. qPCR PR and test PR comparison\n\ndata %&gt;% na.omit() %&gt;% ggplot(aes(x=week)) +\n  geom_line(aes(y=case_prop_pos_7dma*100)) +\n  geom_line(aes(y=pr_7dma, color=\"red\"))\n\n\n\n\n\n\n8. VL and test PR comparison\n\ndata %&gt;% na.omit() %&gt;% ggplot(aes(x=week)) +\n  geom_line(aes(y=case_pcr_pos_7dma)) +\n  geom_line(aes(y=pr_7dma, color=\"red\"))\n\n\n\n\n\n\n9. Test admin\n\ndata %&gt;% na.omit() %&gt;% autoplot(pcr_tests)"
  },
  {
    "objectID": "code/analysis/3_exploratory_timeseries.html#notes",
    "href": "code/analysis/3_exploratory_timeseries.html#notes",
    "title": "Exploratory - Time series",
    "section": "Notes",
    "text": "Notes\n\nall time series follow roughly the same trend\npeaks happen roughly twice per year, the first during the fall (Aug-Oct, potentially influenced by student population influx) and second during the winter (Dec-Feb)\ntests reported, in general, peak during peak transmission times, but that trend does not continue past the beginning of 2022 (see 9. Test admin), indicating the shift to at-home testing and subsequent under-reporting\nit may make sense to split at March-April 2022 as correlations between wastewater metrics and case metrics could weaken past this point"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Data Repository",
    "section": "",
    "text": "Purpose\nPhD Chapter 1 data repository\nExploring COVID-19 forecasting methods using wastewater surveillance data\n\n\nScripts\n\nInitial Data Cleaning\nData Preprocessing\nExploratory Time Series Analysis\nUnivariate Linear Regressions"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html",
    "href": "code/analysis/4_univariate_regressions.html",
    "title": "Univariate Linear Regressions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nlibrary(forecast)\nlibrary(tidymodels)"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#load-packages",
    "href": "code/analysis/4_univariate_regressions.html#load-packages",
    "title": "Univariate Linear Regressions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nlibrary(forecast)\nlibrary(tidymodels)"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#load-data",
    "href": "code/analysis/4_univariate_regressions.html#load-data",
    "title": "Univariate Linear Regressions",
    "section": "Load data",
    "text": "Load data\n\ndata &lt;- readRDS(here(\"data/processed_data/covid_wbe_7dma_weekly.rds\")) %&gt;% \n  mutate(log10_vl_7dma=log10(vl_7dma),\n         log_case_pos_7dma=log(case_pcr_pos_7dma),\n         case_prop_pos_7dma=case_prop_pos_7dma*100,\n         log_case_prop_pos_7dma=log(case_prop_pos_7dma),\n         log_pr_7dma=log(pr_7dma))\n\n#certain variables have been transformed due to distribution abnormality, with some distributions being normalized by certain transformations\n\n#i wanted to build models with both transformed and non-transformed data to compare performances"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#data-splitting",
    "href": "code/analysis/4_univariate_regressions.html#data-splitting",
    "title": "Univariate Linear Regressions",
    "section": "Data splitting",
    "text": "Data splitting\nSee notes on script 3 for details\n\ndata_train_dates &lt;- data %&gt;% head(n = 92) #selects dates before or on the 13th week of 2022 (end of March)\nsplit &lt;- initial_split(data_train_dates, prop=8/10) #reserve 20% of observations at random to do validation\nset.seed(13)\ntrain &lt;- training(split) #create dataset to train models with\n\nset.seed(16)\ntest &lt;- testing(split) #create smaller dataset to do model performance validation with"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#define-model",
    "href": "code/analysis/4_univariate_regressions.html#define-model",
    "title": "Univariate Linear Regressions",
    "section": "Define model",
    "text": "Define model\n\nlr &lt;- linear_reg()\nnull &lt;- null_model() %&gt;% set_engine(\"parsnip\") %&gt;% set_mode(\"regression\")"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#a-log10-viral-load-as-predictor",
    "href": "code/analysis/4_univariate_regressions.html#a-log10-viral-load-as-predictor",
    "title": "Univariate Linear Regressions",
    "section": "A) Log10 Viral load as predictor",
    "text": "A) Log10 Viral load as predictor\n\n1. Positive test count 7DMA ~ VL 7DMA\n\nViz\n\nhist(log(data$case_pcr_pos_7dma)) #check distribution of dependent variable (more normal when natural log transformed)\n\n\n\nhist(log10(data$vl_7dma)) #distribution of independent variable (somewhat normally distributed)\n\n\n\nplot(log10(case_pcr_pos_7dma)~ log10(vl_7dma), data=data)\n\n\n\n\n\n\nModel\n\nrecipe1 &lt;- recipe(case_pcr_pos_7dma ~ log10_vl_7dma, data = train) #recipe \n####################################################################################\nworkflow1 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe1) #model workflow\n####################################################################################\nset.seed(13)\nfit1 &lt;- workflow1 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit1) \n\n# A tibble: 2 × 5\n  term          estimate std.error statistic       p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)     -1338.     204.      -6.56 0.0000000104 \n2 log10_vl_7dma     108.      15.9      6.78 0.00000000428\n\n####################################################################################\naug_train1 &lt;- augment(fit1, train)\naug_train1 %&gt;% select(case_pcr_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   case_pcr_pos_7dma  .pred\n               &lt;dbl&gt;  &lt;dbl&gt;\n 1             11.9   51.7 \n 2            115.    17.7 \n 3              8.07   7.70\n 4             16.5   71.4 \n 5             54.6  NaN   \n 6             75.4   50.1 \n 7             19.9   20.0 \n 8             48.6  102.  \n 9             62.6   18.7 \n10             58.1  NaN   \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds1 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_pcr_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv1 &lt;- fit_resamples(workflow1, resamples = folds1)\ncv1_metrics &lt;- collect_metrics(cv1)\ncv1_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   46.8      25  2.16   Preprocessor1_Model1\n2 rsq     standard    0.425    25  0.0376 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null1 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe1)\n\nnull_cv_metrics1 &lt;- fit_resamples(workflow_null1, resamples = folds1)\n\ncollect_metrics(null_cv_metrics1) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    55.7    25    3.85 Preprocessor1_Model1\n2 rsq     standard   NaN       0   NA    Preprocessor1_Model1\n\n####################################################################################\nrmse1 &lt;- aug_train1 %&gt;% rmse(truth = case_pcr_pos_7dma, .pred)\nrsq1 &lt;- aug_train1 %&gt;% rsq(truth = case_pcr_pos_7dma, .pred)\nm1_metrics &lt;- full_join(rmse1, rsq1)\nm1_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard      46.0  \n2 rsq     standard       0.414\n\n####################################################################################\naug_train1 %&gt;% ggplot(aes(case_pcr_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 6 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 6 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n2. Natural log positive test count 7DMA ~ log10 VL 7DMA\n\nViz\n\nhist(data$log_case_pos_7dma) #check distribution of dependent variable (more normal when natural log transformed)\n\n\n\nhist(log10(data$vl_7dma)) #distribution of independent variable (somewhat normally distributed)\n\n\n\nplot(log_case_pos_7dma~ log10(vl_7dma), data=data)\n\n\n\n\n\n\nModel\n\nrecipe2 &lt;- recipe(log_case_pos_7dma ~ log10_vl_7dma, data = train) #recipe \n####################################################################################\nworkflow2 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe2) #model workflow\n####################################################################################\nset.seed(13)\nfit2 &lt;- workflow2 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit2) \n\n# A tibble: 2 × 5\n  term          estimate std.error statistic    p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)     -23.0      4.84      -4.76 0.0000112 \n2 log10_vl_7dma     2.03     0.377      5.39 0.00000105\n\n####################################################################################\naug_train2 &lt;- augment(fit2, train)\naug_train2 %&gt;% select(log_case_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   log_case_pos_7dma  .pred\n               &lt;dbl&gt;  &lt;dbl&gt;\n 1              2.47   3.17\n 2              4.74   2.53\n 3              2.09   2.34\n 4              2.80   3.54\n 5              4.00 NaN   \n 6              4.32   3.14\n 7              2.99   2.57\n 8              3.88   4.12\n 9              4.14   2.55\n10              4.06 NaN   \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds2 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = log_case_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv2 &lt;- fit_resamples(workflow2, resamples = folds2)\ncv2_metrics &lt;- collect_metrics(cv2)\ncv2_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   1.10     25  0.0298 Preprocessor1_Model1\n2 rsq     standard   0.312    25  0.0293 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null2 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe2)\n\nnull_cv_metrics2 &lt;- fit_resamples(workflow_null2, resamples = folds2)\n\ncollect_metrics(null_cv_metrics2) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     1.27    25  0.0487 Preprocessor1_Model1\n2 rsq     standard   NaN        0 NA      Preprocessor1_Model1\n\n####################################################################################\nrmse2 &lt;- aug_train2 %&gt;% rmse(truth = log_case_pos_7dma, .pred)\nrsq2 &lt;- aug_train2 %&gt;% rsq(truth = log_case_pos_7dma, .pred)\nm2_metrics &lt;- full_join(rmse2, rsq2)\nm2_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       1.09 \n2 rsq     standard       0.309\n\n####################################################################################\naug_train2 %&gt;% ggplot(aes(log_case_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 6 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 6 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n3. Test positivity rate 7DMA ~ log10 VL 7DMA\n\nhist(data$case_prop_pos_7dma) #check distribution of dependent variable (somewhat skewed)\n\n\n\nhist(log10(data$vl_7dma)) #distribution of independent variable (somewhat normally except for observations near LOD\n\n\n\nplot(case_prop_pos_7dma ~ log10(vl_7dma), data=data)\n\n\n\n\n\nModel\n\nrecipe3 &lt;- recipe(case_prop_pos_7dma ~ log10_vl_7dma, data = train) #recipe \n####################################################################################\nworkflow3 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe3) #model workflow\n####################################################################################\nset.seed(13)\nfit3 &lt;- workflow3 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit3) \n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     -204.      25.4      -8.03 2.56e-11\n2 log10_vl_7dma     16.7      1.98      8.41 5.40e-12\n\n####################################################################################\naug_train3 &lt;- augment(fit3, train)\naug_train3 %&gt;% select(case_prop_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   case_prop_pos_7dma  .pred\n                &lt;dbl&gt;  &lt;dbl&gt;\n 1               3.99  10.7 \n 2              15.7    5.48\n 3               4.76   3.93\n 4               5.73  13.8 \n 5              12.0  NaN   \n 6              15.1   10.5 \n 7               4.91   5.83\n 8              12.0   18.5 \n 9              14.1    5.62\n10              13.1  NaN   \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds3 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv3 &lt;- fit_resamples(workflow3, resamples = folds3)\ncv3_metrics &lt;- collect_metrics(cv3)\ncv3_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   5.83     25  0.169  Preprocessor1_Model1\n2 rsq     standard   0.522    25  0.0369 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null3 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe3)\n\nnull_cv_metrics3 &lt;- fit_resamples(workflow_null3, resamples = folds3)\n\ncollect_metrics(null_cv_metrics3) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     7.87    25   0.357 Preprocessor1_Model1\n2 rsq     standard   NaN        0  NA     Preprocessor1_Model1\n\n####################################################################################\nrmse3 &lt;- aug_train3 %&gt;% rmse(truth = case_prop_pos_7dma, .pred)\nrsq3 &lt;- aug_train3 %&gt;% rsq(truth = case_prop_pos_7dma, .pred)\nm3_metrics &lt;- full_join(rmse3, rsq3)\nm3_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       5.72 \n2 rsq     standard       0.521\n\n####################################################################################\naug_train3 %&gt;% ggplot(aes(case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 6 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 6 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n4. Natural log test positivity rate 7DMA ~ log10 VL 7DMA\n\nhist(data$log_case_prop_pos_7dma*100) #check distribution of dependent variable (more normally distributed)\n\n\n\nhist(log10(data$vl_7dma)) #distribution of independent variable (somewhat normally distributed except values near LOD)\n\n\n\nplot(log_case_prop_pos_7dma*100 ~ log10(vl_7dma), data=data)\n\n\n\n\n\nModel\n\nrecipe4 &lt;- recipe(log_case_prop_pos_7dma ~ log10_vl_7dma, data = train) #recipe \n####################################################################################\nworkflow4 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe4) #model workflow\n####################################################################################\nset.seed(13)\nfit4 &lt;- workflow4 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit4) \n\n# A tibble: 2 × 5\n  term          estimate std.error statistic       p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)     -15.8      2.60      -6.07 0.0000000731 \n2 log10_vl_7dma     1.38     0.203      6.83 0.00000000347\n\n####################################################################################\naug_train4 &lt;- augment(fit4, train)\naug_train4 %&gt;% select(log_case_prop_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   log_case_prop_pos_7dma  .pred\n                    &lt;dbl&gt;  &lt;dbl&gt;\n 1                   1.38   2.06\n 2                   2.75   1.62\n 3                   1.56   1.49\n 4                   1.75   2.31\n 5                   2.48 NaN   \n 6                   2.72   2.04\n 7                   1.59   1.65\n 8                   2.48   2.70\n 9                   2.64   1.63\n10                   2.58 NaN   \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds4 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = log_case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv4 &lt;- fit_resamples(workflow4, resamples = folds4)\ncv4_metrics &lt;- collect_metrics(cv4)\ncv4_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.583    25  0.0194 Preprocessor1_Model1\n2 rsq     standard   0.416    25  0.0361 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null4 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe4)\n\nnull_cv_metrics4 &lt;- fit_resamples(workflow_null4, resamples = folds4)\n\ncollect_metrics(null_cv_metrics4) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     0.746    25  0.0214 Preprocessor1_Model1\n2 rsq     standard   NaN         0 NA      Preprocessor1_Model1\n\n####################################################################################\nrmse4 &lt;- aug_train4 %&gt;% rmse(truth = log_case_prop_pos_7dma, .pred)\nrsq4 &lt;- aug_train4 %&gt;% rsq(truth = log_case_prop_pos_7dma, .pred)\nm4_metrics &lt;- full_join(rmse4, rsq4)\nm4_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.585\n2 rsq     standard       0.418\n\n####################################################################################\naug_train4 %&gt;% ggplot(aes(log_case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 6 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 6 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#b-qpcr-positivity-rate-as-predictor",
    "href": "code/analysis/4_univariate_regressions.html#b-qpcr-positivity-rate-as-predictor",
    "title": "Univariate Linear Regressions",
    "section": "B) qPCR positivity rate as predictor",
    "text": "B) qPCR positivity rate as predictor\n\n1. Positive test 7DMA ~ WW PR 7DMA\n\nViz\n\nhist(log10(data$case_pcr_pos_7dma)) #check distribution of dependent variable, more normal when log transformed\n\n\n\nhist(data$pr_7dma) #distribution of independent variable \n\n\n\nplot(log10(case_pcr_pos_7dma) ~ pr_7dma, data=data) #log-transformed looks better\n\n\n\nplot(case_pcr_pos_7dma ~ pr_7dma, data=data) \n\n\n\n\n\n\nModel\n\nrecipe5 &lt;- recipe(case_pcr_pos_7dma ~ pr_7dma, data = train) #recipe \n####################################################################################\nworkflow5 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe5) #model workflow\n####################################################################################\nset.seed(13)\nfit5 &lt;- workflow5 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit5) \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)    -4.38     9.98     -0.439 0.662       \n2 pr_7dma         1.50     0.236     6.36  0.0000000273\n\n####################################################################################\naug_train5 &lt;- augment(fit5, train)\naug_train5 %&gt;% select(case_pcr_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   case_pcr_pos_7dma  .pred\n               &lt;dbl&gt;  &lt;dbl&gt;\n 1             11.9   40.4 \n 2            115.    36.5 \n 3              8.07   3.91\n 4             16.5   72.1 \n 5             54.6  NaN   \n 6             75.4   61.1 \n 7             19.9   47.6 \n 8             48.6  123.  \n 9             62.6   40.9 \n10             58.1  NaN   \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds5 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_pcr_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv5 &lt;- fit_resamples(workflow5, resamples = folds5)\ncv5_metrics &lt;- collect_metrics(cv5)\ncv5_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   48.3      25  2.89   Preprocessor1_Model1\n2 rsq     standard    0.480    25  0.0416 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null5 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe5)\n\nnull_cv_metrics5 &lt;- fit_resamples(workflow_null5, resamples = folds5)\n\ncollect_metrics(null_cv_metrics5) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    55.7    25    3.85 Preprocessor1_Model1\n2 rsq     standard   NaN       0   NA    Preprocessor1_Model1\n\n####################################################################################\nrmse5 &lt;- aug_train5 %&gt;% rmse(truth = case_pcr_pos_7dma, .pred)\nrsq5 &lt;- aug_train5 %&gt;% rsq(truth = case_pcr_pos_7dma, .pred)\nm5_metrics &lt;- full_join(rmse5, rsq5)\nm5_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard      47.3  \n2 rsq     standard       0.395\n\n####################################################################################\naug_train5 %&gt;% ggplot(aes(case_pcr_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 9 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 9 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n2. Natural log positive test count\n\nModel\n\nrecipe6 &lt;- recipe(log_case_pos_7dma ~ pr_7dma, data = train) #recipe \n####################################################################################\nworkflow6 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe6) #model workflow\n####################################################################################\nset.seed(13)\nfit6 &lt;- workflow6 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit6) \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   1.94     0.197        9.87 2.50e-14\n2 pr_7dma       0.0347   0.00465      7.46 3.45e-10\n\n####################################################################################\naug_train6 &lt;- augment(fit6, train)\naug_train6 %&gt;% select(log_case_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   log_case_pos_7dma  .pred\n               &lt;dbl&gt;  &lt;dbl&gt;\n 1              2.47   2.98\n 2              4.74   2.89\n 3              2.09   2.13\n 4              2.80   3.71\n 5              4.00 NaN   \n 6              4.32   3.46\n 7              2.99   3.15\n 8              3.88   4.89\n 9              4.14   2.99\n10              4.06 NaN   \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds6 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = log_case_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv6 &lt;- fit_resamples(workflow6, resamples = folds6)\ncv6_metrics &lt;- collect_metrics(cv6)\ncv6_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.952    25  0.0290 Preprocessor1_Model1\n2 rsq     standard   0.498    25  0.0279 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null6 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe6)\n\nnull_cv_metrics6 &lt;- fit_resamples(workflow_null6, resamples = folds6)\n\ncollect_metrics(null_cv_metrics6) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     1.27    25  0.0487 Preprocessor1_Model1\n2 rsq     standard   NaN        0 NA      Preprocessor1_Model1\n\n####################################################################################\nrmse6 &lt;- aug_train6 %&gt;% rmse(truth = log_case_pos_7dma, .pred)\nrsq6 &lt;- aug_train6 %&gt;% rsq(truth = log_case_pos_7dma, .pred)\nm6_metrics &lt;- full_join(rmse6, rsq6)\nm6_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.933\n2 rsq     standard       0.473\n\n####################################################################################\naug_train6 %&gt;% ggplot(aes(log_case_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 9 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 9 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n3. Test positivity rate 7DMA ~ WW PR 7DMA\n\nViz\n\nhist(data$case_prop_pos_7dma) #check distribution of dependent variable \n\n\n\nhist(data$pr_7dma) #distribution of independent variable \n\n\n\nplot(case_prop_pos_7dma ~ pr_7dma, data=data)\n\n\n\n\n\n\nModel\n\nrecipe7 &lt;- recipe(case_prop_pos_7dma ~ pr_7dma, data = train) #recipe \n####################################################################################\nworkflow7 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe7) #model workflow\n####################################################################################\nset.seed(13)\nfit7 &lt;- workflow7 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit7) \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    1.62     1.18        1.38 1.72e- 1\n2 pr_7dma        0.244    0.0278      8.79 1.70e-12\n\n####################################################################################\naug_train7 &lt;- augment(fit7, train)\naug_train7 %&gt;% select(case_prop_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   case_prop_pos_7dma  .pred\n                &lt;dbl&gt;  &lt;dbl&gt;\n 1               3.99   8.91\n 2              15.7    8.29\n 3               4.76   2.97\n 4               5.73  14.1 \n 5              12.0  NaN   \n 6              15.1   12.3 \n 7               4.91  10.1 \n 8              12.0   22.4 \n 9              14.1    8.99\n10              13.1  NaN   \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds7 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv7 &lt;- fit_resamples(workflow7, resamples = folds7)\ncv7_metrics &lt;- collect_metrics(cv7)\ncv7_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   5.85     25  0.347  Preprocessor1_Model1\n2 rsq     standard   0.613    25  0.0317 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null7 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe7)\n\nnull_cv_metrics7 &lt;- fit_resamples(workflow_null7, resamples = folds7)\n\ncollect_metrics(null_cv_metrics7) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     7.87    25   0.357 Preprocessor1_Model1\n2 rsq     standard   NaN        0  NA     Preprocessor1_Model1\n\n####################################################################################\nrmse7 &lt;- aug_train7 %&gt;% rmse(truth = case_prop_pos_7dma, .pred)\nrsq7 &lt;- aug_train7 %&gt;% rsq(truth = case_prop_pos_7dma, .pred)\nm7_metrics &lt;- full_join(rmse7, rsq7)\nm7_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       5.57 \n2 rsq     standard       0.555\n\n####################################################################################\naug_train7 %&gt;% ggplot(aes(case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 9 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 9 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#log-qpcr-positivity-rate-as-predictor",
    "href": "code/analysis/4_univariate_regressions.html#log-qpcr-positivity-rate-as-predictor",
    "title": "Univariate Linear Regressions",
    "section": "4. Log qPCR positivity rate as predictor",
    "text": "4. Log qPCR positivity rate as predictor\n\nTest positivity rate 7DMA ~ Log WW PR\n\nViz\n\nhist(data$case_prop_pos_7dma) #check distribution of dependent variable \n\n\n\nhist(data$log_pr_7dma) #distribution of independent variable \n\n\n\nplot(case_prop_pos_7dma ~ log_pr_7dma, data=data)\n\n\n\n\n\n\nModel\n\nrecipe8 &lt;- recipe(case_prop_pos_7dma ~ log_pr_7dma, data = train) #recipe \n####################################################################################\nworkflow8 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe8) #model workflow\n####################################################################################\nset.seed(13)\nfit8 &lt;- workflow8 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit8) \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    -6.56     2.21      -2.96 4.26e- 3\n2 log_pr_7dma     5.11     0.669      7.64 1.37e-10\n\n####################################################################################\naug_train8 &lt;- augment(fit8, train)\naug_train8 %&gt;% select(case_prop_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   case_prop_pos_7dma  .pred\n                &lt;dbl&gt;  &lt;dbl&gt;\n 1              9.02   8.96 \n 2             15.5   16.2  \n 3              5.70  12.4  \n 4             15.0   16.4  \n 5              3.83   4.55 \n 6              4.03  10.3  \n 7              4.36  11.7  \n 8              0.592 -0.868\n 9              1.84   7.96 \n10              9.99  10.5  \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds8 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv8 &lt;- fit_resamples(workflow8, resamples = folds8)\ncv8_metrics &lt;- collect_metrics(cv8)\ncv8_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   5.10     25  0.286  Preprocessor1_Model1\n2 rsq     standard   0.561    25  0.0214 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null8 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe8)\n\nnull_cv_metrics8 &lt;- fit_resamples(workflow_null8, resamples = folds8)\n\ncollect_metrics(null_cv_metrics8) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     6.70    25   0.321 Preprocessor1_Model1\n2 rsq     standard   NaN        0  NA     Preprocessor1_Model1\n\n####################################################################################\nrmse8 &lt;- aug_train8 %&gt;% rmse(truth = case_prop_pos_7dma, .pred)\nrsq8 &lt;- aug_train8 %&gt;% rsq(truth = case_prop_pos_7dma, .pred)\nm8_metrics &lt;- full_join(rmse8, rsq8)\nm8_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       5.12 \n2 rsq     standard       0.477\n\n####################################################################################\naug_train8 %&gt;% ggplot(aes(case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 7 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 7 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#notes",
    "href": "code/analysis/4_univariate_regressions.html#notes",
    "title": "Univariate Linear Regressions",
    "section": "Notes",
    "text": "Notes\n\nModel B3 seems to be performing the best so far (out of A1-4, B1-4) but no model is significantly out-performing the others yet\nMany distributions are not normal and transformations do not help with normality, is this still okay to do linear regressions with?\nWhat if something is potentially bimodally distributed? (see histogram for pr_7dma)"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#next-steps-as-of-111723",
    "href": "code/analysis/4_univariate_regressions.html#next-steps-as-of-111723",
    "title": "Univariate Linear Regressions",
    "section": "Next Steps (as of 11/17/23)",
    "text": "Next Steps (as of 11/17/23)\n\nneed to do model validation steps with the reserved 20% testing data\nneed to see how models will perform on the testing dates (April 2022-end of series)\nneed to build more univariate models, then move on to multivariates"
  },
  {
    "objectID": "aboutme.html#leah-lariscy-second-year-phd-student",
    "href": "aboutme.html#leah-lariscy-second-year-phd-student",
    "title": "About Me!",
    "section": "",
    "text": "University of Georgia Environmental Health Science\n\n\n\nErin Lipp\nTravis Glenn"
  },
  {
    "objectID": "aboutme.html#leah-lariscy-2nd-year-phd-student",
    "href": "aboutme.html#leah-lariscy-2nd-year-phd-student",
    "title": "About me!",
    "section": "",
    "text": "University of Georgia Environmental Health Science\n\n\n\nErin Lipp\nTravis Glenn\n\n\n\nAndreas Handel"
  },
  {
    "objectID": "code/analysis/4_univariate_regressions.html#c-log-qpcr-positivity-rate-as-predictor",
    "href": "code/analysis/4_univariate_regressions.html#c-log-qpcr-positivity-rate-as-predictor",
    "title": "Univariate Linear Regressions",
    "section": "C) Log qPCR positivity rate as predictor",
    "text": "C) Log qPCR positivity rate as predictor\n\n1. Test positivity rate 7DMA ~ Log WW PR\n\nViz\n\nhist(data$case_prop_pos_7dma) #check distribution of dependent variable \n\n\n\nhist(data$log_pr_7dma) #distribution of independent variable \n\n\n\nplot(case_prop_pos_7dma ~ log_pr_7dma, data=data)\n\n\n\n\n\n\nModel\n\nrecipe8 &lt;- recipe(case_prop_pos_7dma ~ log_pr_7dma, data = train) #recipe \n####################################################################################\nworkflow8 &lt;- workflow() %&gt;% \n  add_model(lr) %&gt;% \n  add_recipe(recipe8) #model workflow\n####################################################################################\nset.seed(13)\nfit8 &lt;- workflow8 %&gt;% \n  fit(data = train) #fit model to data\n\ntidy(fit8) \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)    -8.83     2.93      -3.01 0.00378      \n2 log_pr_7dma     5.88     0.886      6.64 0.00000000913\n\n####################################################################################\naug_train8 &lt;- augment(fit8, train)\naug_train8 %&gt;% select(case_prop_pos_7dma, .pred) #make predictions on train data\n\n# A tibble: 73 × 2\n   case_prop_pos_7dma  .pred\n                &lt;dbl&gt;  &lt;dbl&gt;\n 1               3.99  11.1 \n 2              15.7   10.6 \n 3               4.76   1.22\n 4               5.73  14.3 \n 5              12.0  NaN   \n 6              15.1   13.4 \n 7               4.91  12.0 \n 8              12.0   17.3 \n 9              14.1   11.2 \n10              13.1  NaN   \n# … with 63 more rows\n\n####################################################################################\nset.seed(13)\nfolds8 &lt;- vfold_cv(train, v = 5, repeats = 5, strata = case_prop_pos_7dma)\n\nWarning: The number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\nThe number of observations in each quantile is below the recommended threshold of 20.\n• Stratification will use 3 breaks instead.\n\nset.seed(13)\ncv8 &lt;- fit_resamples(workflow8, resamples = folds8)\ncv8_metrics &lt;- collect_metrics(cv8)\ncv8_metrics #check cross validation metrics\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   6.49     25  0.247  Preprocessor1_Model1\n2 rsq     standard   0.464    25  0.0214 Preprocessor1_Model1\n\n####################################################################################\nworkflow_null8 &lt;- workflow() %&gt;% \n  add_model(null) %&gt;% \n  add_recipe(recipe8)\n\nnull_cv_metrics8 &lt;- fit_resamples(workflow_null8, resamples = folds8)\n\ncollect_metrics(null_cv_metrics8) #check null model\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     7.87    25   0.357 Preprocessor1_Model1\n2 rsq     standard   NaN        0  NA     Preprocessor1_Model1\n\n####################################################################################\nrmse8 &lt;- aug_train8 %&gt;% rmse(truth = case_prop_pos_7dma, .pred)\nrsq8 &lt;- aug_train8 %&gt;% rsq(truth = case_prop_pos_7dma, .pred)\nm8_metrics &lt;- full_join(rmse8, rsq8)\nm8_metrics #check metrics of predictions on train data\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       6.39 \n2 rsq     standard       0.415\n\n####################################################################################\naug_train8 %&gt;% ggplot(aes(case_prop_pos_7dma, .pred)) +\n  geom_point() +\n  stat_smooth(method = \"lm\") #check actual vs predicted\n\nWarning: Removed 9 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 9 rows containing missing values (`geom_point()`)."
  }
]